# app/services/ai_service.py

"""
Servicio de IA para Flou - Tutor Metamotivacional
Basado en Miele & Scholer (2016) y el modelo de Task-Motivation Fit
Usa Google Gemini 2.5 Pro para extracciÃ³n de slots y generaciÃ³n de respuestas
"""

import logging
import re
import json
from typing import Optional, Dict, List, Tuple
import google.generativeai as genai

from app.core.config import settings
from app.schemas.chat import (
    SessionStateSchema, Slots, EvalResult,
    Sentimiento, TipoTarea, Fase, Plazo, TiempoBloque
)

logger = logging.getLogger(__name__)

# Configurar Gemini
genai.configure(api_key=settings.GEMINI_API_KEY)

# Nombre de la IA
AI_NAME = 'Flou'

# Modelo por defecto (exportado para compatibilidad con wellness.py)
model = genai.GenerativeModel('gemini-2.0-flash-exp')


# ---------------------------- PROMPT DE SISTEMA ---------------------------- #

def get_system_prompt() -> str:
    """Retorna el prompt de sistema completo para Flou"""
    return f"""
Eres {AI_NAME}, una tutora de motivaciÃ³n que ayuda a estudiantes universitarios.

TU PERSONALIDAD:
- Hablas de forma cercana y amigable, como una compaÃ±era mayor
- Eres empÃ¡tica y validates las emociones antes de dar consejos
- Explicas todo con lenguaje simple y cotidiano
- NO uses tÃ©rminos acadÃ©micos complicados ni sÃ­mbolos extraÃ±os (evita: â†‘â†“Â·â†’)
- Usa emojis ocasionales para dar calidez ðŸ˜Š

TU OBJETIVO:
Ayudar al estudiante a encontrar la mejor forma de trabajar segÃºn:
1. CÃ³mo se siente ahora (aburrido, ansioso, frustrado, etc.)
2. QuÃ© tiene que hacer (ensayo, ejercicios, lectura, etc.)
3. Para cuÃ¡ndo lo necesita
4. En quÃ© etapa estÃ¡ (empezando, haciendo, revisando)

CÃ“MO DAS CONSEJOS:
1. Primero valida su emociÃ³n: "Entiendo que te sientas asÃ­ cuando..."
2. Explica brevemente POR QUÃ‰ puede sentirse asÃ­
3. Da UNA estrategia concreta y especÃ­fica (no listas genÃ©ricas)
4. La estrategia debe tener:
   - Una tarea pequeÃ±a y clara que puede hacer YA
   - Tiempo sugerido realista (10-25 minutos)
   - CÃ³mo sabrÃ¡ que terminÃ³
5. Termina con una pregunta abierta para seguir conversando

EJEMPLOS DE BUEN CONSEJO:

Mal: "Delimita alcance mÃ­nimo: termina SOLO la primera micro-parte"
Bien: "Â¿QuÃ© tal si solo escribes las 3 ideas principales en bullets? Sin redactar nada, solo las ideas clave. Unos 10 minutos. Cuando tengas esas 3 ideas, ya avanzaste."

Mal: "Checklist de 3 Ã­tems antes de cerrar: objetivo, evidencia/criterio"
Bien: "Revisa solo la primera pÃ¡gina buscando estos 3 puntos: Â¿tiene sentido cada oraciÃ³n? Â¿las palabras estÃ¡n bien escritas? Â¿usaste bien las comas? 12 minutos, pÃ¡gina por pÃ¡gina."

REGLAS IMPORTANTES:
- Responde en espaÃ±ol normal de Chile (no jergas ni modismos)
- MÃ¡ximo 200 palabras por respuesta (puedes extenderte si es necesario explicar bien)
- Si detectas riesgo de suicidio, di: "Por favor llama al 4141 (lÃ­nea MINSAL gratuita). EstÃ¡n para ayudarte 24/7"
- MantÃ©n la conversaciÃ³n fluida, recuerda lo que el estudiante te contÃ³ antes
- Adapta tus consejos a lo que ya han intentado juntos
- NUNCA muestres al usuario cosas tÃ©cnicas como "Ajuste inferido: AÂ·â†‘" o sÃ­mbolos como â†‘â†“Â·â†’
- NO uses plantillas visibles, habla naturalmente

CÃ³mo estructurar tu respuesta:

- Dale una **estrategia concreta** (mÃ¡ximo 3 pasos simples) con UNA sub-tarea verificable (p.ej., "solo escribe 5 ideas principales" / "solo haz la IntroducciÃ³n" / "solo resuelve 5 ejercicios").

- Sugiere un **bloque de tiempo corto:** 12â€“15 min (o el tiempo que el estudiante indicÃ³).

- **PregÃºntale cÃ³mo le fue:** Al final, pregunta si logrÃ³ la tarea y cÃ³mo se siente ahora.

- Cierra con una pregunta amigable para mantener la conversaciÃ³n.

RECUERDA: NO muestres clasificaciones tÃ©cnicas (A, B, â†‘, â†“, promociÃ³n, prevenciÃ³n, etc.) al usuario.

RESPONDE SIEMPRE DE FORMA NATURAL Y CONVERSACIONAL.
"""


# ---------------------------- DETECCIÃ“N DE CRISIS ---------------------------- #

def detect_crisis(text: str) -> bool:
    """Detecta menciones de riesgo vital"""
    crisis_regex = r'(suicid|quitarme la vida|no quiero vivir|hacerme daÃ±o|matarme)'
    return bool(re.search(crisis_regex, text, re.IGNORECASE))


# ---------------------------- EXTRACCIÃ“N HEURÃSTICA ---------------------------- #

def guess_plazo(text: str) -> Optional[str]:
    """Extrae plazo del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'hoy|hoy dÃ­a|ahora', text_lower):
        return "hoy"
    if re.search(r'maÃ±ana|24\s*h', text_lower):
        return "<24h"
    if re.search(r'prÃ³xima semana|la otra semana|esta semana', text_lower):
        return "esta_semana"
    if re.search(r'mes|semanas|>\s*1', text_lower):
        return ">1_semana"
    return None


def guess_tipo_tarea(text: str) -> Optional[str]:
    """Extrae tipo de tarea del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'ensayo|essay', text_lower):
        return "ensayo"
    if re.search(r'esquema|outline', text_lower):
        return "esquema"
    if re.search(r'borrador|draft', text_lower):
        return "borrador"
    if re.search(r'presentaci(Ã³n|on)|slides', text_lower):
        return "presentacion"
    if re.search(r'proof|corregir|correcci(Ã³n|on)|edita(r|ciÃ³n)', text_lower):
        return "proofreading"
    if re.search(r'mcq|alternativa(s)?|test', text_lower):
        return "mcq"
    if re.search(r'protocolo|laboratorio|lab', text_lower):
        return "protocolo_lab"
    if re.search(r'problema(s)?|ejercicio(s)?|cÃ¡lculo', text_lower):
        return "resolver_problemas"
    if re.search(r'lectura|paper|art[iÃ­]culo', text_lower):
        return "lectura_tecnica"
    if re.search(r'resumen|sintetizar', text_lower):
        return "resumen"
    if re.search(r'c(Ã³|o)digo|bug|programa', text_lower):
        return "coding_bugfix"
    return None


def guess_fase(text: str) -> Optional[str]:
    """Extrae fase del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'ide(a|aciÃ³n)|brainstorm', text_lower):
        return "ideacion"
    if re.search(r'plan', text_lower):
        return "planificacion"
    if re.search(r'escribir|redacci(Ã³n|on)|hacer|resolver', text_lower):
        return "ejecucion"
    if re.search(r'revis(ar|iÃ³n)|editar|proof', text_lower):
        return "revision"
    return None


def guess_sentimiento(text: str) -> Optional[str]:
    """Extrae sentimiento del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'frustra', text_lower):
        return "frustracion"
    if re.search(r'ansiedad|miedo a equivocarme|nervios', text_lower):
        return "ansiedad_error"
    if re.search(r'aburri', text_lower):
        return "aburrimiento"
    if re.search(r'dispers|rumi', text_lower):
        return "dispersion_rumiacion"
    if re.search(r'autoeficacia baja|no puedo|no soy capaz', text_lower):
        return "baja_autoeficacia"
    return None


def guess_ramo(text: str) -> Optional[str]:
    """Extrae nombre del ramo usando regex"""
    match = re.search(r'para (el |la )?([A-Za-zÃÃ‰ÃÃ“ÃšÃ¡Ã©Ã­Ã³ÃºÃ±Ã‘ ]{3,30})', text, re.IGNORECASE)
    if match:
        return match.group(2).strip()
    return None


# ---------------------------- EXTRACCIÃ“N CON LLM ---------------------------- #

async def extract_slots_with_llm(free_text: str, current_slots: Slots) -> Slots:
    """
    Extrae slots estructurados del texto libre usando Gemini 2.5 Pro
    """
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        sys_prompt = """Extrae como JSON compacto los campos del texto del usuario:
- sentimiento: aburrimiento|frustracion|ansiedad_error|dispersion_rumiacion|baja_autoeficacia|otro
- sentimiento_otro: texto libre si es "otro"
- tipo_tarea: ensayo|esquema|borrador|lectura_tecnica|resumen|resolver_problemas|protocolo_lab|mcq|presentacion|coding_bugfix|proofreading
- ramo: nombre del ramo/materia
- plazo: hoy|<24h|esta_semana|>1_semana
- fase: ideacion|planificacion|ejecucion|revision
- tiempo_bloque: 10|12|15|25

Si un campo no aparece, usa null. Responde SOLO con JSON vÃ¡lido, sin texto adicional."""

        user_prompt = f"""Texto del usuario: "{free_text}"

Slots actuales: {current_slots.model_dump_json()}

JSON extraÃ­do:"""

        response = llm_model.generate_content(
            f"{sys_prompt}\n\n{user_prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=500
            )
        )
        
        raw = response.text.strip()
        
        # Extraer JSON del texto
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            parsed = json.loads(json_match.group(0))
        else:
            parsed = json.loads(raw)
        
        # Construir Slots con fallback a valores actuales
        return Slots(
            sentimiento=parsed.get('sentimiento') or current_slots.sentimiento,
            sentimiento_otro=parsed.get('sentimiento_otro') or current_slots.sentimiento_otro,
            tipo_tarea=parsed.get('tipo_tarea') or current_slots.tipo_tarea,
            ramo=parsed.get('ramo') or current_slots.ramo,
            plazo=parsed.get('plazo') or current_slots.plazo,
            fase=parsed.get('fase') or current_slots.fase,
            tiempo_bloque=parsed.get('tiempo_bloque') or current_slots.tiempo_bloque
        )
        
    except Exception as e:
        logger.warning(f"Error en extracciÃ³n LLM, usando heurÃ­stica: {e}")
        # Fallback a heurÃ­stica
        return extract_slots_heuristic(free_text, current_slots)


def extract_slots_heuristic(free_text: str, current_slots: Slots) -> Slots:
    """ExtracciÃ³n heurÃ­stica de slots como fallback"""
    return Slots(
        sentimiento=guess_sentimiento(free_text) or current_slots.sentimiento,
        tipo_tarea=guess_tipo_tarea(free_text) or current_slots.tipo_tarea,
        ramo=guess_ramo(free_text) or current_slots.ramo,
        plazo=guess_plazo(free_text) or current_slots.plazo,
        fase=guess_fase(free_text) or current_slots.fase,
        tiempo_bloque=current_slots.tiempo_bloque or 12
    )


# ---------------------------- CLASIFICACIÃ“N Q2/Q3 ---------------------------- #

def infer_q2_q3(slots: Slots) -> Tuple[str, str, str]:
    """
    Infiere Q2 (A/B), Q3 (â†‘/â†“/mixto) y enfoque (promocion/prevencion)
    """
    # Q2: Demanda creativa (A) vs analÃ­tica (B)
    A_tasks = ["ensayo", "esquema", "borrador", "presentacion"]
    B_tasks = ["proofreading", "mcq", "protocolo_lab", "resolver_problemas", 
               "coding_bugfix", "lectura_tecnica", "resumen"]
    
    Q2 = "A"
    if slots.tipo_tarea in B_tasks:
        Q2 = "B"
    if slots.fase == "revision" or slots.plazo in ["hoy", "<24h"]:
        Q2 = "B"
    if slots.fase in ["ideacion", "planificacion"]:
        Q2 = "A"
    
    # Q3: Nivel de abstracciÃ³n (â†‘ por quÃ© / â†“ cÃ³mo)
    Q3 = "â†“"
    if slots.fase in ["ideacion", "planificacion"]:
        Q3 = "â†‘"
    if slots.fase == "revision" or slots.plazo in ["hoy", "<24h"]:
        Q3 = "â†“"
    
    # Mixto: ensayos suelen necesitar ambos
    if slots.tipo_tarea == "ensayo" and slots.fase in ["planificacion", "ejecucion"]:
        Q3 = "mixto"
    
    # Enfoque regulatorio
    enfoque = "promocion_eager" if Q2 == "A" else "prevencion_vigilant"
    
    return Q2, Q3, enfoque


# ---------------------------- ORQUESTADOR PRINCIPAL ---------------------------- #

async def handle_user_turn(session: SessionStateSchema, user_text: str, context: str = "", chat_history: Optional[List] = None) -> Tuple[str, SessionStateSchema, Optional[List[Dict[str, str]]]]:
    """
    Orquestador principal del flujo metamotivacional.
    Retorna (respuesta_texto, session_actualizada, quick_replies)
    """
    
    # 1) Crisis
    if detect_crisis(user_text):
        crisis_msg = "Escucho que estÃ¡s en un momento muy difÃ­cil. Por favor, busca apoyo inmediato: **llama al 4141** (lÃ­nea gratuita y confidencial del MINSAL). No estÃ¡s sola/o."
        return crisis_msg, session, None
    
    # 2) Saludo Ãºnico
    if not session.greeted:
        session.greeted = True
        welcome = "ðŸ˜Š Â¿CÃ³mo estÃ¡ tu motivaciÃ³n hoy?"
        quick_replies = [
            {"label": "ðŸ˜‘ Aburrimiento", "value": "Siento aburrimiento"},
            {"label": "ðŸ˜¤ FrustraciÃ³n", "value": "Siento frustraciÃ³n"},
            {"label": "ðŸ˜° Ansiedad", "value": "Siento ansiedad"},
            {"label": "ðŸŒ€ DispersiÃ³n", "value": "Siento dispersiÃ³n"},
            {"label": "ðŸ˜” Baja motivaciÃ³n", "value": "Tengo baja motivaciÃ³n"},
            {"label": "ðŸ’­ Otro", "value": "Siento otra cosa"}
        ]
        return welcome, session, quick_replies
    
    # 3) ExtracciÃ³n de slots
    try:
        new_slots = await extract_slots_with_llm(user_text, session.slots)
    except Exception as e:
        logger.error(f"Error en extracciÃ³n de slots: {e}")
        new_slots = extract_slots_heuristic(user_text, session.slots)
    
    session.slots = new_slots
    
    # 4) Si falta dato clave, preguntar (solo en las primeras interacciones)
    missing = []
    if not new_slots.tipo_tarea:
        missing.append("tipo_tarea")
    if not new_slots.fase:
        missing.append("fase")
    if not new_slots.plazo:
        missing.append("plazo")
    if not new_slots.tiempo_bloque:
        missing.append("tiempo_bloque")
    
    # Preguntar si faltan datos importantes y aÃºn no hemos iterado mucho
    if missing and session.iteration < 2:
        priority = ["tipo_tarea", "plazo", "fase", "tiempo_bloque"]
        want = next((k for k in priority if k in missing), None)
        quick_replies = None
        
        if want == "tipo_tarea":
            q = "Â¿QuÃ© tipo de trabajo tienes que hacer?"
            quick_replies = [
                {"label": "ðŸ“ Escribir algo", "value": "Tengo que escribir un trabajo"},
                {"label": "ðŸ“– Leer/Estudiar", "value": "Tengo que leer y estudiar"},
                {"label": "ðŸ§® Resolver ejercicios", "value": "Tengo que resolver ejercicios"},
                {"label": "ðŸ” Revisar/Corregir", "value": "Tengo que revisar mi trabajo"}
            ]
        elif want == "fase":
            q = "Â¿En quÃ© etapa estÃ¡s?"
            quick_replies = [
                {"label": "ðŸ’¡ ReciÃ©n empezando", "value": "Estoy en la fase de ideacion"},
                {"label": "ðŸ“‹ Planificando", "value": "Estoy en la fase de planificacion"},
                {"label": "âœï¸ Haciendo el trabajo", "value": "Estoy en la fase de ejecucion"},
                {"label": "ðŸ” Revisando", "value": "Estoy en la fase de revision"}
            ]
        elif want == "plazo":
            q = "Â¿Para cuÃ¡ndo lo necesitas?"
            quick_replies = [
                {"label": "ðŸ”¥ Hoy", "value": "Es para hoy"},
                {"label": "â° MaÃ±ana", "value": "Es para maÃ±ana"},
                {"label": "ðŸ“… Esta semana", "value": "Es para esta semana"},
                {"label": "ðŸ—“ï¸ MÃ¡s adelante", "value": "Tengo mÃ¡s de una semana"}
            ]
        else:
            q = "Â¿CuÃ¡nto tiempo tienes disponible ahora?"
            quick_replies = [
                {"label": "âš¡ 10 min", "value": "10"},
                {"label": "ðŸŽ¯ 15 min", "value": "15"},
                {"label": "ðŸ’ª 25 min", "value": "25"},
                {"label": "ðŸ”¥ MÃ¡s tiempo", "value": "Tengo mÃ¡s tiempo"}
            ]
        
        return q, session, quick_replies
    
    # Defaults prudentes
    if not new_slots.tiempo_bloque:
        new_slots.tiempo_bloque = 15
        session.slots.tiempo_bloque = 12
    
    # 5) Inferir Q2, Q3, enfoque
    Q2, Q3, enfoque = infer_q2_q3(new_slots)
    session.Q2 = Q2
    session.Q3 = Q3
    session.enfoque = enfoque
    session.tiempo_bloque = new_slots.tiempo_bloque
    
    if not session.sentimiento_inicial and new_slots.sentimiento:
        session.sentimiento_inicial = new_slots.sentimiento
    
    session.sentimiento_actual = new_slots.sentimiento or session.sentimiento_actual
    
    # PRIMERO: Verificar si el usuario aceptÃ³ ir a bienestar (antes de otras detecciones)
    if "quiero probar un ejercicio de bienestar" in user_text.lower() or "DERIVAR_BIENESTAR" in user_text.upper():
        session.iteration = 0  # Reset para cuando vuelva
        session.last_eval_result = EvalResult(fallos_consecutivos=0)
        reply = "Perfecto ðŸ˜Š Voy a llevarte a la secciÃ³n de Bienestar. Elige el ejercicio que mÃ¡s te llame la atenciÃ³n y tÃ³mate tu tiempo. Cuando termines, vuelve aquÃ­ y seguimos con tu tarea con energÃ­a renovada."
        quick_replies = [
            {"label": "ðŸŒ¿ Ir a Bienestar", "value": "NAVIGATE_WELLNESS"}
        ]
        return reply, session, quick_replies
    
    # Detectar respuestas de evaluaciÃ³n del usuario
    # IMPORTANTE: Verificar frases negativas PRIMERO (mÃ¡s especÃ­ficas)
    respuestas_sin_mejora = [
        "no funcionÃ³", "no funciono", "no me funcionÃ³", "no me ayudÃ³", "no me ayudo",
        "sigo igual", "estoy igual", "igual que antes",
        "peor", "me siento peor", "estoy peor", "mÃ¡s mal",
        "no mejorÃ³", "no mejoro", "no ayudÃ³", "no ayudo", 
        "no sirviÃ³", "no sirvio"
    ]
    respuestas_mejora = [
        "me ayudÃ³", "me ayudo", "sÃ­ me ayudÃ³", "si me ayudo",
        "funcionÃ³ bien", "funciono bien", "sÃ­ funcionÃ³", "si funciono",
        "mejor", "me siento mejor", "estoy mejor", "mucho mejor",
        "bien", "muy bien", "genial", "excelente", "perfecto"
    ]
    
    user_text_lower = user_text.lower().strip()
    
    # Verificar sin_mejora PRIMERO (tiene frases mÃ¡s especÃ­ficas con "no")
    sin_mejora = any(frase in user_text_lower for frase in respuestas_sin_mejora)
    # Solo verificar mejora si NO detectÃ³ sin_mejora (para evitar conflictos)
    mejora = False if sin_mejora else any(frase in user_text_lower for frase in respuestas_mejora)
    
    # Si el usuario indica que MEJORÃ“, cerrar con mensaje de despedida
    if mejora and session.iteration > 0:
        session.last_eval_result = EvalResult(fallos_consecutivos=0, cambio_sentimiento="â†‘")
        session.iteration = 0  # Reiniciar para prÃ³xima conversaciÃ³n
        session.greeted = False  # Permitir nuevo saludo en prÃ³xima sesiÃ³n
        
        reply = f"""Â¡QuÃ© bueno escuchar eso! ðŸ˜Š Me alegra mucho que te haya servido.

Recuerda que siempre puedes volver cuando necesites apoyo o una nueva estrategia. Estoy aquÃ­ para ayudarte a encontrar tu mejor forma de trabajar.

Â¡Mucho Ã©xito con tu tarea! ðŸš€"""
        
        return reply, session, None
    
    # Si el usuario indica que NO mejorÃ³, incrementar contador de fallos
    if sin_mejora and session.iteration > 0:
        fallos = session.last_eval_result.fallos_consecutivos if session.last_eval_result else 0
        fallos += 1
        session.last_eval_result = EvalResult(fallos_consecutivos=fallos, cambio_sentimiento="=")
        
        # Verificar INMEDIATAMENTE si debe ofrecer bienestar (â‰¥2 fallos)
        if fallos >= 2:
            reply = f"""Veo que hemos intentado un par de estrategias y todavÃ­a no te sientes mejor ðŸ˜”

A veces lo que sentimos no es solo un tema de organizaciÃ³n o mÃ©todo de estudio. El cuerpo y la mente necesitan un respiro antes de seguir intentando.

Â¿QuÃ© te parece si primero hacemos un ejercicio breve de bienestar? Hay algunos de respiraciÃ³n, relajaciÃ³n o mindfulness que pueden ayudarte a resetear.

Solo toma 3-5 minutos y despuÃ©s volvemos con tu tarea. Â¿Quieres probar?"""
            
            quick_replies = [
                {"label": "âœ… SÃ­, vamos a intentarlo", "value": "SÃ­, quiero probar un ejercicio de bienestar"},
                {"label": "ðŸ”„ No, sigamos con estrategias", "value": "No gracias, sigamos intentando con otras estrategias"}
            ]
            
            # Reset del contador para que no siga ofreciendo
            session.last_eval_result = EvalResult(fallos_consecutivos=0)
            
            return reply, session, quick_replies
        
        # ****** INICIO DE LA NUEVA LÃ“GICA DE RECALIBRACIÃ“N (SI FALLOS=1) ******
        if fallos < 2:
            logger.info(f"Recalibrando estrategia... (Fallo {fallos})")
            
            # 1. Cambiar Q3 (de â†‘â†’â†“ o viceversa)
            if session.Q3 == "â†‘":
                session.Q3 = "â†“"
            elif session.Q3 == "â†“":
                session.Q3 = "â†‘"
            
            # 2. Ajustar tamaÃ±o de tarea (hacerla mÃ¡s pequeÃ±a)
            if session.tiempo_bloque and session.tiempo_bloque > 10:
                session.tiempo_bloque = 10  # Forzar bloque mÃ¡s corto
            else:
                session.tiempo_bloque = 10
            
            # Actualizar los slots para que la generaciÃ³n de respuesta use el tiempo acortado
            session.slots.tiempo_bloque = 10
            logger.info(f"Nueva Q3: {session.Q3}, Nuevo tiempo: {session.tiempo_bloque}")
        # ****** FIN DE LA NUEVA LÃ“GICA DE RECALIBRACIÃ“N ******
        
        # Si aÃºn no llega a 2 fallos, continuar para generar nueva estrategia
        # NO hacer return aquÃ­, dejar que el cÃ³digo siga y genere nueva estrategia
    
    # 7) Generar respuesta conversacional usando Gemini con historial
    try:
        llm_model = genai.GenerativeModel(
            model_name='gemini-2.0-flash-exp',
            system_instruction=get_system_prompt()
        )
        
        # Construir el historial de conversaciÃ³n para Gemini
        history = []
        if chat_history:
            for msg in chat_history[:-1]:  # Excluir el Ãºltimo mensaje del usuario (ya lo pasaremos aparte)
                history.append({
                    "role": "user" if msg["role"] == "user" else "model",
                    "parts": [msg["text"]]
                })
        
        # Agregar contexto adicional si existe
        info_contexto = f"""
[Info contextual - Ãºsala para personalizar tu respuesta]:
- Sentimiento: {new_slots.sentimiento or 'no especificado'}
- Tarea: {new_slots.tipo_tarea or 'no especificada'} {f"de {new_slots.ramo}" if new_slots.ramo else ""}
- Plazo: {new_slots.plazo or 'no especificado'}
- Fase: {new_slots.fase or 'no especificada'}
- Tiempo disponible: {new_slots.tiempo_bloque or 15} minutos
{context if context else ""}
"""
        
        # Iniciar chat con historial
        chat = llm_model.start_chat(history=history)
        
        # Enviar mensaje actual con contexto
        full_message = f"{info_contexto}\n\nEstudiante: {user_text}"
        response = chat.send_message(
            full_message,
            generation_config=genai.types.GenerationConfig(
                temperature=0.8,
                max_output_tokens=400,  # Aumentado para dar mejores explicaciones
                top_p=0.95
            )
        )
        
        reply = response.text.strip()
        
    except Exception as e:
        logger.error(f"Error generando respuesta conversacional: {e}")
        # Fallback simple y empÃ¡tico
        reply = f"Entiendo, cuÃ©ntame un poco mÃ¡s sobre lo que necesitas hacer. Â¿QuÃ© tipo de trabajo es y para cuÃ¡ndo lo necesitas?"
    
    session.iteration += 1
    session.last_strategy = reply
    
    # Si ya dio una estrategia (iteration >= 1), preguntar si funcionÃ³
    # La primera iteraciÃ³n es el saludo, desde la segunda ya da estrategias
    if session.iteration >= 1:
        quick_replies = [
            {"label": "âœ… Me ayudÃ³, me siento mejor", "value": "me ayudÃ³"},
            {"label": "ðŸ˜ Sigo igual", "value": "sigo igual"},
            {"label": "ðŸ˜Ÿ Me siento peor", "value": "no funcionÃ³"}
        ]
    else:
        # Solo en el primer mensaje (saludo), dejar fluir la conversaciÃ³n
        quick_replies = None
    
    return reply, session, quick_replies


# ---------------------------- FUNCIONES AUXILIARES ---------------------------- #

async def generate_chat_response(user_message: str, context: Optional[str] = None) -> str:
    """
    LEGACY: Mantiene compatibilidad con cÃ³digo anterior.
    No usa el sistema metamotivacional completo.
    """
    logger.warning("Usando generate_chat_response legacy - considera migrar a handle_user_turn")
    
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        full_prompt = get_system_prompt() + "\n\n"
        if context:
            full_prompt += f"{context}\n\n"
        full_prompt += f"El usuario pregunta: \"{user_message}\""
        
        response = llm_model.generate_content(
            full_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=300
            )
        )
        
        return response.text
        
    except Exception as error:
        logger.error(f"Error en la llamada a Gemini: {error}")
        return "Lo siento, tuve un problema para procesar tu solicitud. Por favor, intenta de nuevo."


async def generate_profile_summary(profile: dict) -> str:
    """Genera un resumen del perfil del usuario usando Gemini"""
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        summary_prompt = f"""
### Rol
Eres {AI_NAME}, un asistente de IA empÃ¡tico y perspicaz. Tu objetivo es analizar los datos del perfil de un usuario y generar un resumen breve (2-3 frases), positivo y constructivo.

### Tarea
Basado en los siguientes datos del perfil en formato JSON, crea un resumen que destaque sutilmente sus fortalezas o Ã¡reas de autoconocimiento, sin sonar clÃ­nico ni crÃ­tico. El tono debe ser de apoyo, como una reflexiÃ³n amigable. No menciones los datos directamente, sino la idea que transmiten.

### Ejemplo
- Si el usuario trabaja y tiene responsabilidades familiares, podrÃ­as decir: "Veo que gestionas mÃºltiples responsabilidades, lo que habla de tu gran capacidad de organizaciÃ³n y compromiso."
- Si el usuario menciona seguimiento en salud mental, podrÃ­as decir: "Es valiente y muy positivo que te ocupes activamente de tu bienestar emocional."

### Datos del Perfil del Usuario:
{json.dumps(profile, indent=2, ensure_ascii=False)}

### Tu Resumen:
"""
        
        response = llm_model.generate_content(
            summary_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=200
            )
        )
        
        return response.text
        
    except Exception as error:
        logger.error(f"Error al generar el resumen del perfil: {error}")
        return ""

