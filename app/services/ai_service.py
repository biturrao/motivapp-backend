# app/services/ai_service.py

"""
Servicio de IA para Flou - Tutor Metamotivacional
Basado en Miele & Scholer (2016) y el modelo de Task-Motivation Fit
Usa Google gemini-1.5-flash para extracciÃ³n de slots y generaciÃ³n de respuestas
"""

import logging
import re
import json
import time
import uuid
from typing import Optional, Dict, List, Tuple, AsyncGenerator
from datetime import datetime
import google.generativeai as genai

from app.core.config import settings
from app.schemas.chat import (
    SessionStateSchema, Slots,
    Sentimiento, TipoTarea, Fase, Plazo, TiempoBloque
)
from app.services.strategies import (
    obtener_ejemplos_estrategias,
    seleccionar_estrategia,
    EnfoqueRegulatorio,
    NivelConstruccion
)

# Configurar structured logging para observabilidad
logger = logging.getLogger(__name__)

# Structured logging helper
def log_structured(level: str, event: str, **kwargs):
    """Helper para logging estructurado con contexto completo"""
    log_data = {
        "timestamp": datetime.utcnow().isoformat(),
        "event": event,
        "service": "ai_service",
        **kwargs
    }
    getattr(logger, level)(json.dumps(log_data))

# Configurar Gemini
genai.configure(api_key=settings.GEMINI_API_KEY)

# Nombre de la IA
AI_NAME = 'Flou'

# Modelo por defecto (exportado para compatibilidad con wellness.py)
# Usando gemini-1.5-flash para mayor cuota y estabilidad (vs experimental 2.0)
model = genai.GenerativeModel('gemini-1.5-flash')


# ---------------------------- PROMPT DE SISTEMA ---------------------------- #

def get_system_prompt(enfoque: Optional[str] = None, nivel: Optional[str] = None) -> str:
    """
    Retorna el prompt de sistema completo para Flou con ejemplos contextuales.
    
    Args:
        enfoque: 'promocion_eager' o 'prevencion_vigilant' (opcional)
        nivel: 'â†‘' o 'â†“' (opcional)
    """
    # Base del prompt
    base_prompt = f"""
Eres {AI_NAME}, una experta en MetamotivaciÃ³n que adapta su tono y consejos matemÃ¡ticamente segÃºn el perfil del estudiante.

### TU CEREBRO (CÃ“MO PROCESAR LAS INSTRUCCIONES)
RecibirÃ¡s [INSTRUCCIONES ESTRATÃ‰GICAS] antes de cada mensaje. DEBES MODULAR TU RESPUESTA ASÃ:

SI EL MODO ES "ENTUSIASTA" (Promotion Focus):
- Tono: EnÃ©rgico, rÃ¡pido, enfocado en avanzar y ganar.
- Palabras clave: "Lograr", "Avanzar", "Ganar tiempo", "Genial".
- Estrategia: EnfÃ³cate en la cantidad y la velocidad. Ignora los errores menores por ahora.
- Ejemplos:
  * Tareas creativas â†’ "Escribe todas las ideas sin juzgar"
  * Lluvia de ideas â†’ "Cantidad sobre calidad, despuÃ©s filtramos"
  * Borradores â†’ "Avanza rÃ¡pido, los errores se corrigen despuÃ©s"

SI EL MODO ES "VIGILANTE" (Prevention Focus):
- Tono: Calmado, cuidadoso, analÃ­tico, "Safety first".
- Palabras clave: "Revisar", "Asegurar", "PrecisiÃ³n", "Correcto".
- Estrategia: EnfÃ³cate en la calidad y en evitar errores. Ve lento pero seguro.
- Ejemplos:
  * RevisiÃ³n â†’ "Lee lÃ­nea por lÃ­nea, marca cada error"
  * Tareas de precisiÃ³n â†’ "Checklist: verifica punto por punto"
  * DetecciÃ³n errores â†’ "Lee dos veces: corrido y al revÃ©s"

SI EL NIVEL ES "ABSTRACTO" (Q3 Alto):
- Explica el "POR QUÃ‰" y el propÃ³sito. Conecta con metas futuras.
- No des pasos micro-detallados, da direcciones generales.
- Ejemplos:
  * "Â¿Por quÃ© es importante esto para tu carrera?"
  * "Visualiza cÃ³mo te sentirÃ¡s al terminarlo"
  * "Piensa en el impacto a largo plazo"

SI EL NIVEL ES "CONCRETO" (Q3 Bajo):
- Explica SOLO el "CÃ“MO". Ignora el propÃ³sito general.
- Da instrucciones paso a paso, casi robÃ³ticas pero amables.
- Ejemplos:
  * "1. Abre el documento. 2. Lee el primer pÃ¡rrafo. 3. Corrige las comas."
  * "Paso 1: Timer de 10 min. Paso 2: Escribe sin parar. Paso 3: Guarda."

### ESTRATEGIAS SEGÃšN TASK-MOTIVATION FIT
"""
    
    # Agregar ejemplos especÃ­ficos si hay contexto
    if enfoque and nivel:
        try:
            enfoque_enum = EnfoqueRegulatorio.PROMOCION_EAGER if enfoque == "promocion_eager" else EnfoqueRegulatorio.PREVENCION_VIGILANT
            nivel_enum = NivelConstruccion.ABSTRACTO if nivel == "â†‘" else NivelConstruccion.CONCRETO
            ejemplos = obtener_ejemplos_estrategias(enfoque_enum, nivel_enum)
            base_prompt += ejemplos
        except:
            pass  # Si falla, continÃºa sin ejemplos contextuales
    
    base_prompt += """

### REGLAS DE ORO
1. NUNCA menciones tÃ©rminos tÃ©cnicos como "Promotion Focus" o "Q3". ActÃºa el rol, no lo expliques.
2. Valida la emociÃ³n del usuario en la primera frase.
3. Da UNA sola acciÃ³n especÃ­fica que quepa en el [TIEMPO DISPONIBLE].
4. Si el usuario tiene "Ansiedad" o "Baja Autoeficacia", el MODO VIGILANTE + NIVEL CONCRETO es obligatorio (incluso si la instrucciÃ³n dice otra cosa, prioriza reducir la ansiedad con pasos pequeÃ±os).
5. Usa estrategias comprobadas del Task-Motivation Fit:
   - Tareas creativas â†’ Modo ENTUSIASTA
   - Tareas de precisiÃ³n/errores â†’ Modo VIGILANTE
   - Autocontrol/procrastinaciÃ³n â†’ Nivel ABSTRACTO (conectar con propÃ³sito)
   - Tareas tÃ©cnicas/ejecuciÃ³n â†’ Nivel CONCRETO (pasos especÃ­ficos)

### FORMATO DE RESPUESTA
1. ValidaciÃ³n empÃ¡tica corta (1 frase).
2. La Estrategia (adaptada al MODO y NIVEL indicados).
3. Pregunta de cierre simple (Â¿Te parece bien? / Â¿Le damos?).

MantÃ©n la respuesta bajo 90 palabras. SÃ© "Flou": cercana, chilena natural, usa emojis.

### CRISIS
Si detectas riesgo de suicidio, deriva al 4141 inmediatamente.

RESPONDE SIEMPRE DE FORMA NATURAL Y CONVERSACIONAL.
"""
    
    return base_prompt


# ---------------------------- DETECCIÃ“N DE CRISIS ---------------------------- #

def detect_crisis_regex(text: str) -> bool:
    """DetecciÃ³n bÃ¡sica de crisis usando regex (fallback)"""
    crisis_regex = r'\b(suicid|quitarme la vida|no quiero vivir|hacerme daÃ±o|matarme|terminar con todo|autolesiÃ³n|autolesion|cortarme|acabar con esto|quiero morir|sin salida)\b'
    return bool(re.search(crisis_regex, text, re.IGNORECASE))


async def detect_crisis(text: str) -> Dict[str, any]:
    """
    DetecciÃ³n inteligente de crisis usando LLM con temperatura 0.
    Evita falsos positivos como 'me muero de la risa'.
    
    Returns:
        Dict con 'is_crisis' (bool), 'confidence' (float), 'reason' (str)
    """
    start_time = time.time()
    
    try:
        # Primero verificar con regex para filtrar rÃ¡pido casos obvios
        has_crisis_keywords = detect_crisis_regex(text)
        
        if not has_crisis_keywords:
            log_structured("info", "crisis_check_negative", 
                         text_length=len(text), method="regex", latency_ms=0)
            return {"is_crisis": False, "confidence": 1.0, "reason": "No keywords detected"}
        
        # Si hay keywords, validar con LLM para evitar falsos positivos
        guardrail_model = genai.GenerativeModel('gemini-1.5-flash')
        
        guardrail_prompt = f"""Analiza este mensaje de un estudiante y determina si expresa ideaciÃ³n suicida o riesgo vital REAL.

REGLAS:
- "Me muero de la risa" o "me muero de hambre" NO son crisis.
- Solo es crisis si hay intenciÃ³n explÃ­cita de hacerse daÃ±o o quitarse la vida.
- Responde SOLO con un JSON: {{"is_crisis": true/false, "confidence": 0.0-1.0, "reason": "explicaciÃ³n breve"}}

Mensaje: "{text}"

JSON:"""
        
        response = guardrail_model.generate_content(
            guardrail_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.0,  # DeterminÃ­stico
                max_output_tokens=100
            )
        )
        
        result_text = response.text.strip()
        json_match = re.search(r'\{[\s\S]*\}', result_text)
        
        if json_match:
            result = json.loads(json_match.group(0))
        else:
            result = json.loads(result_text)
        
        latency = (time.time() - start_time) * 1000
        
        log_structured("warning" if result["is_crisis"] else "info",
                     "crisis_check_complete",
                     is_crisis=result["is_crisis"],
                     confidence=result["confidence"],
                     reason=result["reason"],
                     latency_ms=round(latency, 2))
        
        return result
        
    except Exception as e:
        # Fallback a regex en caso de error
        logger.error(f"Error en detecciÃ³n inteligente de crisis: {e}")
        is_crisis = detect_crisis_regex(text)
        return {
            "is_crisis": is_crisis,
            "confidence": 0.5,
            "reason": "Fallback to regex due to error"
        }


# ---------------------------- EXTRACCIÃ“N HEURÃSTICA ---------------------------- #

def guess_plazo(text: str) -> Optional[str]:
    """Extrae plazo del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'hoy|hoy dÃ­a|ahora|en el dÃ­a|para la noche', text_lower):
        return "hoy"
    if re.search(r'maÃ±ana|24\s*h|en un dÃ­a', text_lower):
        return "<24h"
    if re.search(r'prÃ³xima semana|la otra semana|esta semana|en estos dÃ­as|antes del finde', text_lower):
        return "esta_semana"
    if re.search(r'mes|semanas|>\s*1|prÃ³ximo mes|largo plazo', text_lower):
        return ">1_semana"
    return None


def guess_tipo_tarea(text: str) -> Optional[str]:
    """Extrae tipo de tarea del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'ensayo|essay|informe|reporte|escrito', text_lower):
        return "ensayo"
    if re.search(r'esquema|outline|mapa conceptual|diagrama', text_lower):
        return "esquema"
    if re.search(r'borrador|draft|avance', text_lower):
        return "borrador"
    if re.search(r'presentaci(Ã³n|on)|slides|powerpoint|discurso', text_lower):
        return "presentacion"
    if re.search(r'proof|corregir|correcci(Ã³n|on)|edita(r|ciÃ³n)|feedback', text_lower):
        return "proofreading"
    if re.search(r'mcq|alternativa(s)?|test|prueba|examen', text_lower):
        return "mcq"
    if re.search(r'protocolo|laboratorio|lab', text_lower):
        return "protocolo_lab"
    if re.search(r'problema(s)?|ejercicio(s)?|cÃ¡lculo|guÃ­a', text_lower):
        return "resolver_problemas"
    if re.search(r'lectura|paper|art[iÃ­]culo|leer|texto', text_lower):
        return "lectura_tecnica"
    if re.search(r'resumen|sintetizar|sÃ­ntesis', text_lower):
        return "resumen"
    if re.search(r'c(Ã³|o)digo|programar', text_lower) and not re.search(r'bug|error', text_lower):
        return "coding"
    if re.search(r'bug|error|debug', text_lower):
        return "bugfix"
    return None


def guess_fase(text: str) -> Optional[str]:
    """Extrae fase del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'ide(a|aciÃ³n)|brainstorm|empezando|inicio', text_lower):
        return "ideacion"
    if re.search(r'plan|organizar|estructura', text_lower):
        return "planificacion"
    if re.search(r'escribir|redacci(Ã³n|on)|hacer|resolver|desarrollar|avanzando', text_lower):
        return "ejecucion"
    if re.search(r'revis(ar|iÃ³n)|editar|proof|corregir|finalizando|Ãºltimos detalles', text_lower):
        return "revision"
    return None


def guess_sentimiento(text: str) -> Optional[str]:
    """Extrae sentimiento del texto usando heurÃ­stica"""
    text_lower = text.lower()
    if re.search(r'frustra|enojado|molesto|rabia|irritado|impotencia|bloqueado|estancado', text_lower):
        return "frustracion"
    if re.search(r'ansiedad|miedo a equivocarme|nervios|preocupado|estresado|tenso|pÃ¡nico|abrumado|agobiado', text_lower):
        return "ansiedad_error"
    if re.search(r'aburri|lata|paja|sin ganas|monÃ³tono|repetitivo|tedioso|desinterÃ©s', text_lower):
        return "aburrimiento"
    if re.search(r'dispers|distraÃ­do|rumi|dando vueltas|no me concentro|mente en blanco|divago|perdido', text_lower):
        return "dispersion_rumiacion"
    if re.search(r'autoeficacia baja|no puedo|no soy capaz|difÃ­cil|superado|inseguro|incapaz|no lo voy a lograr', text_lower):
        return "baja_autoeficacia"
    return None


def guess_ramo(text: str) -> Optional[str]:
    """Extrae nombre del ramo usando regex"""
    match = re.search(r'para (el |la )?([A-Za-zÃÃ‰ÃÃ“ÃšÃ¡Ã©Ã­Ã³ÃºÃ±Ã‘ ]{3,30})', text, re.IGNORECASE)
    if match:
        return match.group(2).strip()
    return None


# ---------------------------- EXTRACCIÃ“N CON LLM ---------------------------- #

async def extract_slots_with_llm(free_text: str, current_slots: Slots) -> Slots:
    """
    Extrae slots estructurados del texto libre usando Gemini 1.5 Flash
    """
    try:
        llm_model = genai.GenerativeModel('gemini-1.5-flash')
        
        sys_prompt = """Extrae como JSON compacto los campos del texto del usuario:
- sentimiento: aburrimiento|frustracion|ansiedad_error|dispersion_rumiacion|baja_autoeficacia|otro
- sentimiento_otro: texto libre si es "otro"
- tipo_tarea: ensayo|esquema|borrador|lectura_tecnica|resumen|resolver_problemas|protocolo_lab|mcq|presentacion|coding|bugfix|proofreading
- ramo: nombre del ramo/materia
- plazo: hoy|<24h|esta_semana|>1_semana
- fase: ideacion|planificacion|ejecucion|revision
- tiempo_bloque: 10|12|15|25

Si un campo no aparece, usa null. Responde SOLO con JSON vÃ¡lido, sin texto adicional."""

        user_prompt = f"""Texto del usuario: "{free_text}"

Slots actuales: {current_slots.model_dump_json()}

JSON extraÃ­do:"""

        response = llm_model.generate_content(
            f"{sys_prompt}\n\n{user_prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=500
            )
        )
        
        raw = response.text.strip()
        
        # Extraer JSON del texto
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            parsed = json.loads(json_match.group(0))
        else:
            parsed = json.loads(raw)
        
        # Construir Slots con fallback a valores actuales
        return Slots(
            sentimiento=parsed.get('sentimiento') or current_slots.sentimiento,
            sentimiento_otro=parsed.get('sentimiento_otro') or current_slots.sentimiento_otro,
            tipo_tarea=parsed.get('tipo_tarea') or current_slots.tipo_tarea,
            ramo=parsed.get('ramo') or current_slots.ramo,
            plazo=parsed.get('plazo') or current_slots.plazo,
            fase=parsed.get('fase') or current_slots.fase,
            tiempo_bloque=parsed.get('tiempo_bloque') or current_slots.tiempo_bloque
        )
        
    except Exception as e:
        logger.warning(f"Error en extracciÃ³n LLM, usando heurÃ­stica: {e}")
        # Fallback a heurÃ­stica
        return extract_slots_heuristic(free_text, current_slots)


def extract_slots_heuristic(free_text: str, current_slots: Slots) -> Slots:
    """ExtracciÃ³n heurÃ­stica de slots como fallback"""
    return Slots(
        sentimiento=guess_sentimiento(free_text) or current_slots.sentimiento,
        tipo_tarea=guess_tipo_tarea(free_text) or current_slots.tipo_tarea,
        ramo=guess_ramo(free_text) or current_slots.ramo,
        plazo=guess_plazo(free_text) or current_slots.plazo,
        fase=guess_fase(free_text) or current_slots.fase,
        tiempo_bloque=current_slots.tiempo_bloque or 12
    )


# ---------------------------- CLASIFICACIÃ“N Q2/Q3 ---------------------------- #

def infer_q2_q3(slots: Slots) -> Tuple[str, str, str]:
    """
    Infiere Q2 (A/B), Q3 (â†‘/â†“/mixto) y enfoque (promocion/prevencion)
    """
    # Q2: Demanda creativa (A) vs analÃ­tica (B)
    A_tasks = ["ensayo", "esquema", "borrador", "presentacion", "coding"]
    B_tasks = ["proofreading", "mcq", "protocolo_lab", "resolver_problemas", 
               "bugfix", "lectura_tecnica", "resumen"]
    
    Q2 = "A"
    if slots.tipo_tarea in B_tasks:
        Q2 = "B"
    if slots.fase == "revision" or slots.plazo in ["hoy", "<24h"]:
        Q2 = "B"
    if slots.fase in ["ideacion", "planificacion"]:
        Q2 = "A"
    
    # Q3: Nivel de abstracciÃ³n (â†‘ por quÃ© / â†“ cÃ³mo)
    Q3 = "â†“"
    if slots.fase in ["ideacion", "planificacion"]:
        Q3 = "â†‘"
    if slots.fase == "revision" or slots.plazo in ["hoy", "<24h"]:
        Q3 = "â†“"
    
    # Mixto: ensayos suelen necesitar ambos
    if slots.tipo_tarea == "ensayo" and slots.fase in ["planificacion", "ejecucion"]:
        Q3 = "mixto"
    
    # Enfoque regulatorio
    enfoque = "promocion_eager" if Q2 == "A" else "prevencion_vigilant"
    
    return Q2, Q3, enfoque


# ---------------------------- ORQUESTADOR PRINCIPAL ---------------------------- #

async def handle_user_turn(session: SessionStateSchema, user_text: str, context: str = "", chat_history: Optional[List[Dict[str, str]]] = None) -> Tuple[str, SessionStateSchema, Optional[List[Dict[str, str]]]]:
    """
    Orquestador principal del flujo metamotivacional.
    Retorna (respuesta_texto, session_actualizada, quick_replies)
    """
    
    # 1) Crisis detection con LLM inteligente
    crisis_result = await detect_crisis(user_text)
    if crisis_result["is_crisis"] and crisis_result["confidence"] > 0.7:
        log_structured("critical", "crisis_detected", 
                     confidence=crisis_result["confidence"],
                     reason=crisis_result["reason"])
        crisis_msg = "Escucho que estÃ¡s en un momento muy difÃ­cil. Por favor, busca apoyo inmediato: **llama al 4141** (lÃ­nea gratuita y confidencial del MINSAL). No estÃ¡s sola/o."
        return crisis_msg, session, None
    
    # 2) Saludo Ãºnico (si no hay historial y no se ha saludado)
    if not chat_history and not session.greeted:
        session.greeted = True
        welcome = "Hola, soy Flou, tu asistente Task-Motivation. ðŸ˜Š Para empezar, Â¿por quÃ© no me dices cÃ³mo estÃ¡ tu motivaciÃ³n hoy?"
        quick_replies = [
            {"label": "ðŸ˜‘ Aburrido/a", "value": "Estoy aburrido"},
            {"label": "ðŸ˜¤ Frustrado/a", "value": "Estoy frustrado"},
            {"label": "ðŸ˜° Ansioso/a", "value": "Estoy ansioso"},
            {"label": "ðŸŒ€ DistraÃ­do/a", "value": "Estoy distraÃ­do"},
            {"label": "ðŸ˜” Desmotivado/a", "value": "Estoy desmotivado"},
            {"label": "ðŸ˜• Inseguro/a", "value": "Me siento inseguro"},
            {"label": "ðŸ˜© Abrumado/a", "value": "Me siento abrumado"},
        ]
        return welcome, session, quick_replies
    
    # 2.5) Detectar si el usuario quiere reiniciar
    if "reiniciar" in user_text.lower() or user_text.strip().lower() == "reiniciar conversaciÃ³n":
        # Reset completo de la sesiÃ³n
        session.greeted = False
        session.onboarding_complete = False
        session.strategy_given = False
        session.iteration = 0
        session.failed_attempts = 0
        session.Q2 = None
        session.Q3 = None
        session.enfoque = None
        session.tiempo_bloque = None
        session.sentimiento_inicial = None
        session.sentimiento_actual = None
        session.last_strategy = None
        session.slots = Slots()
        
        restart_msg = "Â¡Perfecto! Empecemos de nuevo. ðŸ”„\n\nÂ¿CÃ³mo estÃ¡ tu motivaciÃ³n hoy?"
        quick_replies = [
            {"label": "ðŸ˜‘ Aburrido/a", "value": "Estoy aburrido"},
            {"label": "ðŸ˜¤ Frustrado/a", "value": "Estoy frustrado"},
            {"label": "ðŸ˜° Ansioso/a", "value": "Estoy ansioso"},
            {"label": "ðŸŒ€ DistraÃ­do/a", "value": "Estoy distraÃ­do"},
            {"label": "ðŸ˜” Desmotivado/a", "value": "Estoy desmotivado"},
            {"label": "ðŸ˜• Inseguro/a", "value": "Me siento inseguro"},
            {"label": "ðŸ˜© Abrumado/a", "value": "Me siento abrumado"},
        ]
        
        log_structured("info", "session_restart", request_id="non_streaming")
        return restart_msg, session, quick_replies
    
    # 3) Detectar si es solo un saludo casual
    casual_greetings = ["hola", "hey", "buenos dÃ­as", "buenas tardes", "buenas noches", "quÃ© tal", "saludos", "holi"]
    is_casual_greeting = any(greeting in user_text.lower().strip() for greeting in casual_greetings) and len(user_text.strip()) < 20
    
    # Si es un saludo casual despuÃ©s del saludo inicial, responder de forma conversacional
    if is_casual_greeting and session.greeted and session.iteration == 0:
        casual_response = "Â¡Hola! ðŸ˜Š Estoy aquÃ­ para ayudarte con tu trabajo acadÃ©mico. Â¿QuÃ© necesitas hacer hoy? Puedes contarme sobre alguna tarea o actividad que tengas pendiente."
        session.iteration += 1
        quick_replies = [
            {"label": "ðŸ“ Tengo que estudiar", "value": "Tengo que estudiar"},
            {"label": "âœï¸ Tengo que escribir", "value": "Tengo que escribir algo"},
            {"label": "ðŸ“š Tengo que leer", "value": "Tengo que leer"},
            {"label": "ðŸ¤” No sÃ© por dÃ³nde empezar", "value": "No sÃ© por dÃ³nde empezar"}
        ]
        return casual_response, session, quick_replies
    
    # 4) FLUJO GUIADO POR FASES - Sistema secuencial estricto
    # Fase 1: Sentimiento (obligatorio)
    # Fase 2: Tipo de tarea (obligatorio)
    # Fase 3: Plazo (obligatorio)
    # Fase 4: Fase de trabajo (obligatorio)
    # Fase 5: Tiempo disponible (opcional, tiene default)
    
    # Extraer slots del mensaje actual
    try:
        new_slots = await extract_slots_with_llm(user_text, session.slots)
    except Exception as e:
        logger.error(f"Error en extracciÃ³n de slots: {e}")
        new_slots = extract_slots_heuristic(user_text, session.slots)
    
    # Actualizar slots acumulativos
    session.slots = new_slots
    
    # FASE 1: Si no tiene sentimiento, preguntar PRIMERO
    if not session.slots.sentimiento and session.iteration <= 3:
        session.iteration += 1
        q = "Para poder ayudarte mejor, Â¿cÃ³mo te sientes ahora mismo con tu trabajo?"
        quick_replies = [
            {"label": "ðŸ˜‘ Aburrido/a", "value": "Me siento aburrido"},
            {"label": "ðŸ˜¤ Frustrado/a", "value": "Me siento frustrado"},
            {"label": "ðŸ˜° Ansioso/a por equivocarme", "value": "Tengo ansiedad a equivocarme"},
            {"label": "ðŸŒ€ DistraÃ­do/a o rumiando", "value": "Estoy distraÃ­do y dando vueltas"},
            {"label": "ðŸ˜” Con baja confianza", "value": "Siento que no puedo hacerlo"},
            {"label": "ðŸ˜ Neutral, solo quiero avanzar", "value": "Me siento neutral"}
        ]
        return q, session, quick_replies
    
    # FASE 2: Si tiene sentimiento pero no tipo de tarea, preguntar
    if session.slots.sentimiento and not session.slots.tipo_tarea and session.iteration <= 4:
        session.iteration += 1
        q = "Perfecto. Ahora cuÃ©ntame, Â¿quÃ© tipo de trabajo necesitas hacer?"
        quick_replies = [
            {"label": "ðŸ“ Escribir ensayo/informe", "value": "Tengo que escribir un ensayo"},
            {"label": "ðŸ“– Leer material tÃ©cnico", "value": "Tengo que leer material"},
            {"label": "ðŸ§® Resolver ejercicios", "value": "Tengo que resolver ejercicios"},
            {"label": "ðŸ” Revisar/Corregir", "value": "Tengo que revisar mi trabajo"},
            {"label": "ðŸ’» Programar/Codificar", "value": "Tengo que programar"},
            {"label": "ðŸŽ¤ Preparar presentaciÃ³n", "value": "Tengo que preparar una presentaciÃ³n"}
        ]
        return q, session, quick_replies
    
    # FASE 3: Si tiene sentimiento y tarea, pero no plazo, preguntar
    if session.slots.sentimiento and session.slots.tipo_tarea and not session.slots.plazo and session.iteration <= 5:
        session.iteration += 1
        q = "Entiendo. Â¿Para cuÃ¡ndo necesitas tenerlo listo?"
        quick_replies = [
            {"label": "ðŸ”¥ Hoy mismo", "value": "Es para hoy"},
            {"label": "â° MaÃ±ana (24h)", "value": "Es para maÃ±ana"},
            {"label": "ðŸ“… Esta semana", "value": "Es para esta semana"},
            {"label": "ðŸ—“ï¸ MÃ¡s de 1 semana", "value": "Tengo mÃ¡s de una semana"}
        ]
        return q, session, quick_replies
    
    # FASE 4: Si tiene sentimiento, tarea y plazo, pero no fase, preguntar
    if session.slots.sentimiento and session.slots.tipo_tarea and session.slots.plazo and not session.slots.fase and session.iteration <= 6:
        session.iteration += 1
        q = "Muy bien. Â¿En quÃ© etapa del trabajo estÃ¡s ahora?"
        quick_replies = [
            {"label": "ðŸ’¡ Empezando (Ideas)", "value": "Estoy en la fase de ideacion"},
            {"label": "ðŸ“‹ Planificando", "value": "Estoy en la fase de planificacion"},
            {"label": "âœï¸ Ejecutando/Haciendo", "value": "Estoy en la fase de ejecucion"},
            {"label": "ðŸ” Revisando/Finalizando", "value": "Estoy en la fase de revision"}
        ]
        return q, session, quick_replies
    
    # FASE 5: Si tiene todo menos tiempo, preguntar (Ãºltima pregunta)
    if (session.slots.sentimiento and session.slots.tipo_tarea and 
        session.slots.plazo and session.slots.fase and 
        not session.slots.tiempo_bloque and session.iteration <= 7):
        session.iteration += 1
        q = "Ãšltima pregunta: Â¿CuÃ¡nto tiempo tienes disponible AHORA para trabajar en esto?"
        quick_replies = [
            {"label": "âš¡ 10-12 min (mini sesiÃ³n)", "value": "Tengo 10 minutos"},
            {"label": "ðŸŽ¯ 15-20 min (sesiÃ³n corta)", "value": "Tengo 15 minutos"},
            {"label": "ðŸ’ª 25-30 min (pomodoro)", "value": "Tengo 25 minutos"},
            {"label": "ðŸ”¥ 45+ min (sesiÃ³n larga)", "value": "Tengo 45 minutos"}
        ]
        return q, session, quick_replies
    
    # Defaults prudentes si no se proporcionÃ³ tiempo
    if not session.slots.tiempo_bloque:
        session.slots.tiempo_bloque = 15
        logger.info(f"Usando tiempo por defecto: 15 minutos")
    
    # Marcar onboarding como completo
    if not session.onboarding_complete:
        session.onboarding_complete = True
        logger.info("Onboarding completado - Generando primera estrategia")
    
    # Logging del flujo completado
    log_structured("info", "onboarding_complete",
                 sentimiento=session.slots.sentimiento,
                 tipo_tarea=session.slots.tipo_tarea,
                 plazo=session.slots.plazo,
                 fase=session.slots.fase,
                 tiempo_bloque=session.slots.tiempo_bloque)
    
    # 6) Inferir Q2, Q3, enfoque
    Q2, Q3, enfoque = infer_q2_q3(new_slots)
    session.Q2 = Q2
    session.Q3 = Q3
    session.enfoque = enfoque
    session.tiempo_bloque = new_slots.tiempo_bloque
    
    if not session.sentimiento_inicial and new_slots.sentimiento:
        session.sentimiento_inicial = new_slots.sentimiento
    
    session.sentimiento_actual = new_slots.sentimiento or session.sentimiento_actual
    
    # PRIMERO: Verificar si el usuario aceptÃ³ ir a bienestar (antes de otras detecciones)
    if "quiero probar un ejercicio de bienestar" in user_text.lower() or "NAVIGATE_WELLNESS" in user_text.upper():
        session.iteration = 0  # Reset para cuando vuelva
        session.strategy_given = False
        session.failed_attempts = 0
        reply = "Perfecto ðŸ˜Š Voy a llevarte a la secciÃ³n de Bienestar. Elige el ejercicio que mÃ¡s te llame la atenciÃ³n y tÃ³mate tu tiempo. Cuando termines, vuelve aquÃ­ y seguimos con tu tarea con energÃ­a renovada."
        quick_replies = [
            {"label": "ðŸŒ¿ Ir a Bienestar", "value": "NAVIGATE_WELLNESS"}
        ]
        return reply, session, quick_replies
    
    # SEGUNDO: Si ya se dio una estrategia, esperar evaluaciÃ³n del usuario
    if session.strategy_given:
        # Detectar respuestas de evaluaciÃ³n del usuario
        user_text_lower = user_text.lower().strip()
        
        # IMPORTANTE: Verificar frases negativas PRIMERO (mÃ¡s especÃ­ficas)
        respuestas_sin_mejora = [
            "no funcionÃ³", "no funciono", "no me funcionÃ³", "no me ayudÃ³", "no me ayudo",
            "sigo igual", "estoy igual", "igual que antes",
            "peor", "me siento peor", "estoy peor", "mÃ¡s mal",
            "no mejorÃ³", "no mejoro", "no ayudÃ³", "no ayudo", 
            "no sirviÃ³", "no sirvio", "no sirve"
        ]
        respuestas_mejora = [
            "me ayudÃ³", "me ayudo", "sÃ­ me ayudÃ³", "si me ayudo",
            "funcionÃ³ bien", "funciono bien", "sÃ­ funcionÃ³", "si funciono",
            "me siento mejor", "estoy mejor", "mucho mejor",
            "bien", "muy bien", "genial", "excelente", "perfecto"
        ]
        
        # Verificar sin_mejora PRIMERO (mÃ¡s especÃ­fico)
        sin_mejora = any(frase in user_text_lower for frase in respuestas_sin_mejora)
        
        # Solo verificar mejora si NO es sin_mejora
        if not sin_mejora:
            mejora = any(frase in user_text_lower for frase in respuestas_mejora)
        else:
            mejora = False
        
        # Log para debugging
        log_structured("debug", "evaluation_detection",
                     user_text=user_text_lower[:50],
                     sin_mejora=sin_mejora,
                     mejora=mejora)
        
        # Si el usuario indica que MEJORÃ“, cerrar con mensaje de despedida
        if mejora:
            # Reset completo de la sesiÃ³n
            session.strategy_given = False
            session.onboarding_complete = False
            session.iteration = 0
            session.greeted = False
            session.failed_attempts = 0
            session.Q2 = None
            session.Q3 = None
            session.enfoque = None
            session.tiempo_bloque = None
            session.sentimiento_inicial = None
            session.sentimiento_actual = None
            session.last_strategy = None
            session.slots = Slots()
            
            reply = f"""Â¡QuÃ© bueno escuchar eso! ðŸ˜Š Me alegra mucho que te haya servido.

Recuerda que siempre puedes volver cuando necesites apoyo o una nueva estrategia. Estoy aquÃ­ para ayudarte a encontrar tu mejor forma de trabajar.

Â¡Mucho Ã©xito con tu tarea! ðŸš€"""
            
            return reply, session, None
        
        # Si el usuario indica que NO mejorÃ³, incrementar contador de fallos
        if sin_mejora:
            session.failed_attempts += 1
            
            log_structured("info", "strategy_failure",
                         failed_attempts=session.failed_attempts)
            
            # Verificar INMEDIATAMENTE si debe ofrecer bienestar (â‰¥2 fallos)
            if session.failed_attempts >= 2:
                reply = f"""Entiendo que las estrategias no han funcionado esta vez. ðŸ˜”

A veces necesitamos un enfoque mÃ¡s profundo para gestionar emociones. Te sugiero explorar la **pestaÃ±a de Bienestar** donde encontrarÃ¡s ejercicios de respiraciÃ³n, mindfulness y relajaciÃ³n que pueden ayudarte a resetear.

Â¿Te gustarÃ­a que te lleve allÃ­ ahora?"""
                
                quick_replies = [
                    {"label": "ðŸŒ¿ SÃ­, ir a Bienestar", "value": "NAVIGATE_WELLNESS"},
                    {"label": "ðŸ”„ Reiniciar conversaciÃ³n", "value": "reiniciar"}
                ]
                
                # Resetear flags pero mantener failed_attempts para tracking
                session.strategy_given = False
                session.onboarding_complete = False
                
                log_structured("info", "derivation_to_wellness", request_id="non_streaming")
                
                return reply, session, quick_replies
            
            # Si fallos < 2: Recalibrar y generar nueva estrategia (primera falla = intento 1, segunda estrategia = intento 2)
            if session.failed_attempts == 1:
                logger.info(f"Recalibrando estrategia... (Fallo {session.failed_attempts})")
                
                # 1. Cambiar Q3 (de â†‘â†’â†“ o viceversa)
                if session.Q3 == "â†‘":
                    session.Q3 = "â†“"
                elif session.Q3 == "â†“":
                    session.Q3 = "â†‘"
                
                # 2. Ajustar tamaÃ±o de tarea (hacerla mÃ¡s pequeÃ±a)
                session.tiempo_bloque = 10
                session.slots.tiempo_bloque = 10
                logger.info(f"Nueva Q3: {session.Q3}, Nuevo tiempo: {session.tiempo_bloque}")
                
                # Marcar que NO hay estrategia dada para que genere una nueva
                session.strategy_given = False
                # Continuar el flujo para generar nueva estrategia (no hacer return aquÃ­)
    
    # ProtecciÃ³n: Si ya fallaron 2 estrategias, NO generar mÃ¡s
    if session.failed_attempts >= 2 and session.strategy_given:
        log_structured("warning", "max_attempts_reached",
                     failed_attempts=session.failed_attempts)
        bienestar_fallback = "Ya intentamos varias estrategias. Te recomiendo explorar la **pestaÃ±a de Bienestar** para resetear. ðŸŒ¿"
        quick_replies = [
            {"label": "ðŸŒ¿ SÃ­, ir a Bienestar", "value": "NAVIGATE_WELLNESS"},
            {"label": "ðŸ”„ Reiniciar conversaciÃ³n", "value": "reiniciar"}
        ]
        return bienestar_fallback, session, quick_replies
    
    # 7) Generar respuesta conversacional usando Gemini con historial
    try:
        llm_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash',
            system_instruction=get_system_prompt(enfoque=session.enfoque, nivel=session.Q3)
        )
        
        # Construir el historial de conversaciÃ³n para Gemini
        history = []
        if chat_history:
            for msg in chat_history:
                role = "user" if msg.get("role") == "user" else "model"
                # Asegurarnos de que el contenido es una lista de partes
                parts = msg.get("parts", [])
                if isinstance(parts, str):
                    parts = [parts]
                
                # Si parts estÃ¡ vacÃ­o, intentamos obtenerlo de "text"
                if not parts and "text" in msg:
                    parts = [msg["text"]]

                if parts:
                    history.append({"role": role, "parts": parts})
        
        # Agregar contexto adicional con instrucciones estratÃ©gicas
        # Mapeo legible para el LLM
        modo_instruccion = "VIGILANTE (Evitar errores, ser cuidadoso)" if session.enfoque == "prevencion_vigilant" else "ENTUSIASTA (Avanzar rÃ¡pido, pensar en logros)"
        nivel_instruccion = "CONCRETO (Pasos pequeÃ±os, el 'cÃ³mo')" if session.Q3 == "â†“" else "ABSTRACTO (VisiÃ³n general, el 'por quÃ©')"
        
        info_contexto = f"""
[INSTRUCCIONES ESTRATÃ‰GICAS DEL SISTEMA - OBEDECE ESTOS PARÃMETROS]
1. TU MODO OPERATIVO: {modo_instruccion}
2. TU NIVEL DE DETALLE: {nivel_instruccion}
3. TIEMPO DISPONIBLE: {session.slots.tiempo_bloque or 15} minutos (Ajusta la tarea a este tiempo exacto)

[DATOS DEL USUARIO]
- Sentimiento detectado: {session.slots.sentimiento or 'Neutral'}
- Tarea: {session.slots.tipo_tarea or 'General'}
- Fase: {session.slots.fase or 'No definida'}
- Plazo: {session.slots.plazo or 'No definido'}
{context if context else ""}
"""
        
        # Iniciar chat con historial
        chat = llm_model.start_chat(history=history)
        
        # Enviar mensaje actual con contexto
        full_message = f"{info_contexto}\n\nEstudiante: {user_text}"
        response = chat.send_message(
            full_message,
            generation_config=genai.types.GenerationConfig(
                temperature=0.8,
                max_output_tokens=400,  # Aumentado para dar mejores explicaciones
                top_p=0.95
            )
        )
        
        reply = response.text.strip()
        
    except Exception as e:
        logger.error(f"Error generando respuesta conversacional: {e}")
        # Fallback simple y empÃ¡tico
        reply = f"Entiendo, cuÃ©ntame un poco mÃ¡s sobre lo que necesitas hacer. Â¿QuÃ© tipo de trabajo es y para cuÃ¡ndo lo necesitas?"
    
    session.iteration += 1
    session.last_strategy = reply
    
    # Marcar que se dio una estrategia y esperar evaluaciÃ³n
    session.strategy_given = True
    
    # Siempre dar quick replies de evaluaciÃ³n despuÃ©s de una estrategia
    quick_replies = [
        {"label": "âœ… Me ayudÃ³, me siento mejor", "value": "me ayudÃ³"},
        {"label": "âŒ No funcionÃ³", "value": "no funcionÃ³"}
    ]
    
    return reply, session, quick_replies


# ---------------------------- FUNCIONES DE STREAMING ---------------------------- #

async def handle_user_turn_streaming(
    session: SessionStateSchema,
    user_text: str,
    context: str = "",
    chat_history: Optional[List[Dict[str, str]]] = None
) -> AsyncGenerator[Dict[str, any], None]:
    """
    VersiÃ³n streaming del orquestador metamotivacional.
    Genera chunks de respuesta en tiempo real para UX inmediata.
    
    Yields:
        Dict con 'type' ('chunk'|'metadata'|'complete') y 'data'
    """
    request_id = str(uuid.uuid4())
    start_time = time.time()
    
    log_structured("info", "streaming_request_start",
                 request_id=request_id,
                 user_text_length=len(user_text),
                 session_iteration=session.iteration)
    
    try:
        # 1) Crisis detection (no streaming, debe ser inmediato)
        crisis_result = await detect_crisis(user_text)
        if crisis_result["is_crisis"] and crisis_result["confidence"] > 0.7:
            crisis_msg = "Escucho que estÃ¡s en un momento muy difÃ­cil. Por favor, busca apoyo inmediato: **llama al 4141** (lÃ­nea gratuita y confidencial del MINSAL). No estÃ¡s sola/o."
            yield {"type": "complete", "data": {"text": crisis_msg, "session": session, "quick_replies": None}}
            return
        
        # 2) Saludo (no streaming, es corto)
        if not chat_history and not session.greeted:
            session.greeted = True
            welcome = "Hola, soy Flou, tu asistente Task-Motivation. ðŸ˜Š Para empezar, Â¿por quÃ© no me dices cÃ³mo estÃ¡ tu motivaciÃ³n hoy?"
            quick_replies = [
                {"label": "ðŸ˜‘ Aburrido/a", "value": "Estoy aburrido"},
                {"label": "ðŸ˜¤ Frustrado/a", "value": "Estoy frustrado"},
                {"label": "ðŸ˜° Ansioso/a", "value": "Estoy ansioso"},
                {"label": "ðŸŒ€ DistraÃ­do/a", "value": "Estoy distraÃ­do"},
                {"label": "ðŸ˜” Desmotivado/a", "value": "Estoy desmotivado"},
                {"label": "ðŸ˜• Inseguro/a", "value": "Me siento inseguro"},
                {"label": "ðŸ˜© Abrumado/a", "value": "Me siento abrumado"},
            ]
            yield {"type": "complete", "data": {"text": welcome, "session": session, "quick_replies": quick_replies}}
            return
        
        # 2.5) Detectar si el usuario quiere reiniciar
        if "reiniciar" in user_text.lower() or user_text.strip().lower() == "reiniciar conversaciÃ³n":
            # Reset completo de la sesiÃ³n
            session.greeted = False
            session.onboarding_complete = False
            session.strategy_given = False
            session.iteration = 0
            session.failed_attempts = 0
            session.Q2 = None
            session.Q3 = None
            session.enfoque = None
            session.tiempo_bloque = None
            session.sentimiento_inicial = None
            session.sentimiento_actual = None
            session.last_strategy = None
            session.slots = Slots()
            
            restart_msg = "Â¡Perfecto! Empecemos de nuevo. ðŸ”„\n\nÂ¿CÃ³mo estÃ¡ tu motivaciÃ³n hoy?"
            quick_replies = [
                {"label": "ðŸ˜‘ Aburrido/a", "value": "Estoy aburrido"},
                {"label": "ðŸ˜¤ Frustrado/a", "value": "Estoy frustrado"},
                {"label": "ðŸ˜° Ansioso/a", "value": "Estoy ansioso"},
                {"label": "ðŸŒ€ DistraÃ­do/a", "value": "Estoy distraÃ­do"},
                {"label": "ðŸ˜” Desmotivado/a", "value": "Estoy desmotivado"},
                {"label": "ðŸ˜• Inseguro/a", "value": "Me siento inseguro"},
                {"label": "ðŸ˜© Abrumado/a", "value": "Me siento abrumado"},
            ]
            
            log_structured("info", "session_restart_streaming", request_id=request_id)
            yield {"type": "complete", "data": {"text": restart_msg, "session": session, "quick_replies": quick_replies}}
            return
        
        # 3) Detectar si es solo un saludo casual
        casual_greetings = ["hola", "hey", "buenos dÃ­as", "buenas tardes", "buenas noches", "quÃ© tal", "saludos", "holi"]
        is_casual_greeting = any(greeting in user_text.lower().strip() for greeting in casual_greetings) and len(user_text.strip()) < 20
        
        # Si es un saludo casual despuÃ©s del saludo inicial, responder de forma conversacional
        if is_casual_greeting and session.greeted and session.iteration == 0:
            casual_response = "Â¡Hola! ðŸ˜Š Estoy aquÃ­ para ayudarte con tu trabajo acadÃ©mico. Â¿QuÃ© necesitas hacer hoy? Puedes contarme sobre alguna tarea o actividad que tengas pendiente."
            session.iteration += 1
            quick_replies = [
                {"label": "ðŸ“ Tengo que estudiar", "value": "Tengo que estudiar"},
                {"label": "âœï¸ Tengo que escribir", "value": "Tengo que escribir algo"},
                {"label": "ðŸ“š Tengo que leer", "value": "Tengo que leer"},
                {"label": "ðŸ¤” No sÃ© por dÃ³nde empezar", "value": "No sÃ© por dÃ³nde empezar"}
            ]
            yield {"type": "complete", "data": {"text": casual_response, "session": session, "quick_replies": quick_replies}}
            return
        
        # 4) FLUJO GUIADO POR FASES - Sistema secuencial estricto (versiÃ³n streaming)
        # Fase 1: Sentimiento (obligatorio)
        # Fase 2: Tipo de tarea (obligatorio)
        # Fase 3: Plazo (obligatorio)
        # Fase 4: Fase de trabajo (obligatorio)
        # Fase 5: Tiempo disponible (opcional, tiene default)
        
        # Extraer slots del mensaje actual
        try:
            new_slots = await extract_slots_with_llm(user_text, session.slots)
        except Exception as e:
            logger.error(f"Error en extracciÃ³n de slots: {e}")
            new_slots = extract_slots_heuristic(user_text, session.slots)
        
        # Actualizar slots acumulativos
        session.slots = new_slots
        
        # FASE 1: Si no tiene sentimiento, preguntar PRIMERO
        if not session.slots.sentimiento and session.iteration <= 3:
            session.iteration += 1
            q = "Para poder ayudarte mejor, Â¿cÃ³mo te sientes ahora mismo con tu trabajo?"
            quick_replies = [
                {"label": "ðŸ˜‘ Aburrido/a", "value": "Me siento aburrido"},
                {"label": "ðŸ˜¤ Frustrado/a", "value": "Me siento frustrado"},
                {"label": "ðŸ˜° Ansioso/a por equivocarme", "value": "Tengo ansiedad a equivocarme"},
                {"label": "ðŸŒ€ DistraÃ­do/a o rumiando", "value": "Estoy distraÃ­do y dando vueltas"},
                {"label": "ðŸ˜” Con baja confianza", "value": "Siento que no puedo hacerlo"},
                {"label": "ðŸ˜ Neutral, solo quiero avanzar", "value": "Me siento neutral"}
            ]
            yield {"type": "complete", "data": {"text": q, "session": session, "quick_replies": quick_replies}}
            return
        
        # FASE 2: Si tiene sentimiento pero no tipo de tarea, preguntar
        if session.slots.sentimiento and not session.slots.tipo_tarea and session.iteration <= 4:
            session.iteration += 1
            q = "Perfecto. Ahora cuÃ©ntame, Â¿quÃ© tipo de trabajo necesitas hacer?"
            quick_replies = [
                {"label": "ðŸ“ Escribir ensayo/informe", "value": "Tengo que escribir un ensayo"},
                {"label": "ðŸ“– Leer material tÃ©cnico", "value": "Tengo que leer material"},
                {"label": "ðŸ§® Resolver ejercicios", "value": "Tengo que resolver ejercicios"},
                {"label": "ðŸ” Revisar/Corregir", "value": "Tengo que revisar mi trabajo"},
                {"label": "ðŸ’» Programar/Codificar", "value": "Tengo que programar"},
                {"label": "ðŸŽ¤ Preparar presentaciÃ³n", "value": "Tengo que preparar una presentaciÃ³n"}
            ]
            yield {"type": "complete", "data": {"text": q, "session": session, "quick_replies": quick_replies}}
            return
        
        # FASE 3: Si tiene sentimiento y tarea, pero no plazo, preguntar
        if session.slots.sentimiento and session.slots.tipo_tarea and not session.slots.plazo and session.iteration <= 5:
            session.iteration += 1
            q = "Entiendo. Â¿Para cuÃ¡ndo necesitas tenerlo listo?"
            quick_replies = [
                {"label": "ðŸ”¥ Hoy mismo", "value": "Es para hoy"},
                {"label": "â° MaÃ±ana (24h)", "value": "Es para maÃ±ana"},
                {"label": "ðŸ“… Esta semana", "value": "Es para esta semana"},
                {"label": "ðŸ—“ï¸ MÃ¡s de 1 semana", "value": "Tengo mÃ¡s de una semana"}
            ]
            yield {"type": "complete", "data": {"text": q, "session": session, "quick_replies": quick_replies}}
            return
        
        # FASE 4: Si tiene sentimiento, tarea y plazo, pero no fase, preguntar
        if session.slots.sentimiento and session.slots.tipo_tarea and session.slots.plazo and not session.slots.fase and session.iteration <= 6:
            session.iteration += 1
            q = "Muy bien. Â¿En quÃ© etapa del trabajo estÃ¡s ahora?"
            quick_replies = [
                {"label": "ðŸ’¡ Empezando (Ideas)", "value": "Estoy en la fase de ideacion"},
                {"label": "ðŸ“‹ Planificando", "value": "Estoy en la fase de planificacion"},
                {"label": "âœï¸ Ejecutando/Haciendo", "value": "Estoy en la fase de ejecucion"},
                {"label": "ðŸ” Revisando/Finalizando", "value": "Estoy en la fase de revision"}
            ]
            yield {"type": "complete", "data": {"text": q, "session": session, "quick_replies": quick_replies}}
            return
        
        # FASE 5: Si tiene todo menos tiempo, preguntar (Ãºltima pregunta)
        if (session.slots.sentimiento and session.slots.tipo_tarea and 
            session.slots.plazo and session.slots.fase and 
            not session.slots.tiempo_bloque and session.iteration <= 7):
            session.iteration += 1
            q = "Ãšltima pregunta: Â¿CuÃ¡nto tiempo tienes disponible AHORA para trabajar en esto?"
            quick_replies = [
                {"label": "âš¡ 10-12 min (mini sesiÃ³n)", "value": "Tengo 10 minutos"},
                {"label": "ðŸŽ¯ 15-20 min (sesiÃ³n corta)", "value": "Tengo 15 minutos"},
                {"label": "ðŸ’ª 25-30 min (pomodoro)", "value": "Tengo 25 minutos"},
                {"label": "ðŸ”¥ 45+ min (sesiÃ³n larga)", "value": "Tengo 45 minutos"}
            ]
            yield {"type": "complete", "data": {"text": q, "session": session, "quick_replies": quick_replies}}
            return
        
        # Defaults prudentes si no se proporcionÃ³ tiempo
        if not session.slots.tiempo_bloque:
            session.slots.tiempo_bloque = 15
            logger.info(f"Usando tiempo por defecto: 15 minutos")
        
        # Marcar onboarding como completo
        if not session.onboarding_complete:
            session.onboarding_complete = True
            logger.info("Onboarding completado (streaming) - Generando primera estrategia")
        
        # Logging del flujo completado
        log_structured("info", "onboarding_complete_streaming",
                     request_id=request_id,
                     sentimiento=session.slots.sentimiento,
                     tipo_tarea=session.slots.tipo_tarea,
                     plazo=session.slots.plazo,
                     fase=session.slots.fase,
                     tiempo_bloque=session.slots.tiempo_bloque)
        
        # SEGUNDO: Si ya dimos estrategia, detectar evaluaciÃ³n del usuario (streaming)
        if session.strategy_given:
            user_lower = user_text.lower().strip()
            
            # 1. Detectar evaluaciÃ³n positiva (mejora)
            if any(phrase in user_lower for phrase in ["me ayudÃ³", "me siento mejor", "funcionÃ³", "me sirviÃ³", "mejorÃ©"]):
                # âœ… Ã‰XITO: Despedida y cierre
                despedida = "Â¡Me alegra mucho que te haya servido! ðŸŽ‰ Recuerda que puedes volver cuando necesites apoyo. Â¡Sigue adelante!"
                
                # Resetear sesiÃ³n completamente
                session.greeted = False
                session.onboarding_complete = False
                session.strategy_given = False
                session.iteration = 0
                session.failed_attempts = 0
                session.Q2 = None
                session.Q3 = None
                session.enfoque = None
                session.tiempo_bloque = None
                session.sentimiento_inicial = None
                session.sentimiento_actual = None
                session.last_strategy = None
                session.slots = Slots()
                
                log_structured("info", "success_closure_streaming", request_id=request_id)
                yield {"type": "complete", "data": {"text": despedida, "session": session, "quick_replies": None}}
                return
            
            # 2. Detectar evaluaciÃ³n negativa (sin mejora)
            if any(phrase in user_lower for phrase in ["sigo igual", "no funcionÃ³", "no me sirviÃ³", "me siento peor", "no ayudÃ³"]):
                # Incrementar contador de fallos
                session.failed_attempts += 1
                
                log_structured("info", "strategy_failure_streaming",
                             request_id=request_id,
                             failed_attempts=session.failed_attempts)
                
                # Si ya intentamos 2 veces (primera estrategia + 1 recalibraciÃ³n), derivar a bienestar
                if session.failed_attempts >= 2:
                    bienestar_msg = (
                        "Entiendo que las estrategias no han funcionado esta vez. ðŸ˜”\n\n"
                        "A veces necesitamos un enfoque mÃ¡s profundo para gestionar emociones. "
                        "Te sugiero explorar la **pestaÃ±a de Bienestar** donde encontrarÃ¡s ejercicios de respiraciÃ³n, "
                        "mindfulness y relajaciÃ³n que pueden ayudarte a resetear.\n\n"
                        "Â¿Te gustarÃ­a que te lleve allÃ­ ahora?"
                    )
                    quick_replies = [
                        {"label": "ðŸŒ¿ SÃ­, ir a Bienestar", "value": "NAVIGATE_WELLNESS"},
                        {"label": "ðŸ”„ Reiniciar conversaciÃ³n", "value": "reiniciar"}
                    ]
                    
                    # Resetear flags pero mantener failed_attempts para tracking
                    session.strategy_given = False
                    session.onboarding_complete = False
                    
                    log_structured("info", "derivation_to_wellness_streaming", request_id=request_id)
                    yield {"type": "complete", "data": {"text": bienestar_msg, "session": session, "quick_replies": quick_replies}}
                    return
                
                # Primera falla: recalibrar parÃ¡metros y generar nueva estrategia
                else:
                    recal_msg = (
                        "Entiendo, esa estrategia no te ayudÃ³. ðŸ’­\n\n"
                        "Voy a ajustar el enfoque y proponerte algo diferente que puede funcionar mejor para ti."
                    )
                    
                    # Cambiar Q3 para recalibraciÃ³n (de abstracto a concreto o viceversa)
                    if session.Q3 == "â†‘":
                        session.Q3 = "â†“"
                    elif session.Q3 == "â†“":
                        session.Q3 = "â†‘"
                    
                    # Acortar tiempo de bloque para que sea mÃ¡s manejable
                    if session.tiempo_bloque and session.tiempo_bloque > 10:
                        session.tiempo_bloque = 10
                    
                    # Resetear flag para generar nueva estrategia
                    session.strategy_given = False
                    
                    log_structured("info", "strategy_recalibration_streaming",
                                 request_id=request_id,
                                 new_Q3=session.Q3,
                                 new_tiempo=session.tiempo_bloque)
                    
                    # Enviar mensaje de recalibraciÃ³n y continuar al flujo de generaciÃ³n
                    yield {"type": "chunk", "data": {"text": recal_msg + "\n\n"}}
        
        # ProtecciÃ³n: Si ya fallaron 2 estrategias y de alguna forma llegamos aquÃ­, NO generar mÃ¡s
        if session.failed_attempts >= 2 and session.strategy_given:
            log_structured("warning", "max_attempts_reached_streaming", 
                         request_id=request_id,
                         failed_attempts=session.failed_attempts)
            bienestar_fallback = "Ya intentamos varias estrategias. Te recomiendo explorar la **pestaÃ±a de Bienestar** para resetear. ðŸŒ¿"
            quick_replies = [
                {"label": "ðŸŒ¿ SÃ­, ir a Bienestar", "value": "NAVIGATE_WELLNESS"},
                {"label": "ðŸ”„ Reiniciar conversaciÃ³n", "value": "reiniciar"}
            ]
            yield {"type": "complete", "data": {"text": bienestar_fallback, "session": session, "quick_replies": quick_replies}}
            return
        
        # 6) Inferir Q2, Q3, enfoque
        Q2, Q3, enfoque = infer_q2_q3(session.slots)
        session.Q2 = Q2
        session.Q3 = Q3
        session.enfoque = enfoque
        session.tiempo_bloque = session.slots.tiempo_bloque
        
        if not session.sentimiento_inicial and session.slots.sentimiento:
            session.sentimiento_inicial = session.slots.sentimiento
        
        session.sentimiento_actual = session.slots.sentimiento or session.sentimiento_actual
        
        # Enviar metadata antes de streaming
        metadata_event = {
            "type": "metadata",
            "data": {
                "Q2": Q2,
                "Q3": Q3,
                "enfoque": enfoque,
                "tiempo_bloque": session.tiempo_bloque
            }
        }
        log_structured("info", "metadata_sent", 
                     request_id=request_id,
                     metadata=metadata_event["data"])
        yield metadata_event
        
        # 7) Generar respuesta con STREAMING
        llm_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash',
            system_instruction=get_system_prompt(enfoque=session.enfoque, nivel=session.Q3)
        )
        
        # Construir historial
        history = []
        if chat_history:
            for msg in chat_history:
                role = "user" if msg.get("role") == "user" else "model"
                parts = msg.get("parts", [])
                if isinstance(parts, str):
                    parts = [parts]
                if not parts and "text" in msg:
                    parts = [msg["text"]]
                if parts:
                    history.append({"role": role, "parts": parts})
        
        # Contexto estratÃ©gico
        modo_instruccion = "VIGILANTE (Evitar errores, ser cuidadoso)" if session.enfoque == "prevencion_vigilant" else "ENTUSIASTA (Avanzar rÃ¡pido, pensar en logros)"
        nivel_instruccion = "CONCRETO (Pasos pequeÃ±os, el 'cÃ³mo')" if session.Q3 == "â†“" else "ABSTRACTO (VisiÃ³n general, el 'por quÃ©')"
        
        info_contexto = f"""
[INSTRUCCIONES ESTRATÃ‰GICAS DEL SISTEMA - OBEDECE ESTOS PARÃMETROS]
1. TU MODO OPERATIVO: {modo_instruccion}
2. TU NIVEL DE DETALLE: {nivel_instruccion}
3. TIEMPO DISPONIBLE: {session.slots.tiempo_bloque or 15} minutos (Ajusta la tarea a este tiempo exacto)

[DATOS DEL USUARIO]
- Sentimiento detectado: {session.slots.sentimiento or 'Neutral'}
- Tarea: {session.slots.tipo_tarea or 'General'}
- Fase: {session.slots.fase or 'No definida'}
- Plazo: {session.slots.plazo or 'No definido'}
{context if context else ""}
"""
        
        chat = llm_model.start_chat(history=history)
        full_message = f"{info_contexto}\n\nEstudiante: {user_text}"
        
        log_structured("info", "gemini_request_start",
                     request_id=request_id,
                     message_length=len(full_message),
                     history_count=len(history))
        
        # STREAMING: enviar chunks en tiempo real
        response = chat.send_message(
            full_message,
            generation_config=genai.types.GenerationConfig(
                temperature=0.8,
                max_output_tokens=400,
                top_p=0.95
            ),
            stream=True  # ðŸ”¥ STREAMING ACTIVADO
        )
        
        accumulated_text = ""
        chunk_count = 0
        
        log_structured("info", "streaming_started", request_id=request_id)
        
        for chunk in response:
            if chunk.text:
                accumulated_text += chunk.text
                chunk_count += 1
                yield {
                    "type": "chunk",
                    "data": {"text": chunk.text}
                }
                
                # Log cada 5 chunks para no saturar
                if chunk_count % 5 == 0:
                    log_structured("debug", "streaming_progress",
                                 request_id=request_id,
                                 chunk_count=chunk_count,
                                 accumulated_length=len(accumulated_text))
        
        log_structured("info", "streaming_chunks_complete",
                     request_id=request_id,
                     total_chunks=chunk_count,
                     total_length=len(accumulated_text))
        
        # Actualizar sesiÃ³n
        session.iteration += 1
        session.last_strategy = accumulated_text
        
        # Marcar que se dio una estrategia y esperar evaluaciÃ³n
        session.strategy_given = True
        
        # Siempre dar quick replies de evaluaciÃ³n despuÃ©s de una estrategia
        quick_replies = [
            {"label": "âœ… Me ayudÃ³, me siento mejor", "value": "me ayudÃ³"},
            {"label": "âŒ No funcionÃ³", "value": "no funcionÃ³"}
        ]
        ]
        
        latency = (time.time() - start_time) * 1000
        log_structured("info", "streaming_request_complete",
                     request_id=request_id,
                     chunk_count=chunk_count,
                     total_length=len(accumulated_text),
                     latency_ms=round(latency, 2))
        
        # Enviar evento de completado
        complete_event = {
            "type": "complete",
            "data": {
                "session": session,
                "quick_replies": quick_replies,
                "full_text": accumulated_text
            }
        }
        log_structured("info", "complete_event_sent",
                     request_id=request_id,
                     has_quick_replies=quick_replies is not None,
                     quick_reply_count=len(quick_replies) if quick_replies else 0)
        yield complete_event
        
    except Exception as e:
        log_structured("error", "streaming_request_error",
                     request_id=request_id,
                     error=str(e))
        yield {
            "type": "error",
            "data": {"message": "Error generando respuesta. Intenta nuevamente."}
        }


# ---------------------------- FUNCIONES AUXILIARES ---------------------------- #

async def generate_chat_response(user_message: str, context: Optional[str] = None) -> str:
    """
    LEGACY: Mantiene compatibilidad con cÃ³digo anterior.
    No usa el sistema metamotivacional completo.
    """
    logger.warning("Usando generate_chat_response legacy - considera migrar a handle_user_turn")
    
    try:
        llm_model = genai.GenerativeModel('gemini-1.5-flash')
        
        full_prompt = get_system_prompt() + "\n\n"
        if context:
            full_prompt += f"{context}\n\n"
        full_prompt += f"El usuario pregunta: \"{user_message}\""
        
        response = llm_model.generate_content(
            full_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=300
            )
        )
        
        return response.text
        
    except Exception as error:
        logger.error(f"Error en la llamada a Gemini: {error}")
        return "Lo siento, tuve un problema para procesar tu solicitud. Por favor, intenta de nuevo."


async def generate_profile_summary(profile: dict) -> str:
    """Genera un resumen del perfil del usuario usando Gemini"""
    try:
        llm_model = genai.GenerativeModel('gemini-1.5-flash')
        
        summary_prompt = f"""
### Rol
Eres {AI_NAME}, un asistente de IA empÃ¡tico y perspicaz. Tu objetivo es analizar los datos del perfil de un usuario y generar un resumen breve (2-3 frases), positivo y constructivo.

### Tarea
Basado en los siguientes datos del perfil en formato JSON, crea un resumen que destaque sutilmente sus fortalezas o Ã¡reas de autoconocimiento, sin sonar clÃ­nico ni crÃ­tico. El tono debe ser de apoyo, como una reflexiÃ³n amigable. No menciones los datos directamente, sino la idea que transmiten.

### Ejemplo
- Si el usuario trabaja y tiene responsabilidades familiares, podrÃ­as decir: "Veo que gestionas mÃºltiples responsabilidades, lo que habla de tu gran capacidad de organizaciÃ³n y compromiso."
- Si el usuario menciona seguimiento en salud mental, podrÃ­as decir: "Es valiente y muy positivo que te ocupes activamente de tu bienestar emocional."

### Datos del Perfil del Usuario:
{json.dumps(profile, indent=2, ensure_ascii=False)}

### Tu Resumen:
"""
        
        response = llm_model.generate_content(
            summary_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=200
            )
        )
        
        return response.text
        
    except Exception as error:
        logger.error(f"Error al generar el resumen del perfil: {error}")
        return ""

