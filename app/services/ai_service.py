# app/services/ai_service.py

"""
Servicio de IA para Flou - Tutor Metamotivacional
Basado en Miele & Scholer (2016) y el modelo de Task-Motivation Fit
Usa Google Gemini 2.5 Pro para extracci√≥n de slots y generaci√≥n de respuestas
"""

import logging
import re
import json
from typing import Optional, Dict, List, Tuple
import google.generativeai as genai

from app.core.config import settings
from app.schemas.chat import (
    SessionStateSchema, Slots, EvalResult,
    Sentimiento, TipoTarea, Fase, Plazo, TiempoBloque
)

logger = logging.getLogger(__name__)

# Configurar Gemini
genai.configure(api_key=settings.GEMINI_API_KEY)

# Nombre de la IA
AI_NAME = 'Flou'

# Modelo por defecto (exportado para compatibilidad con wellness.py)
model = genai.GenerativeModel('gemini-2.0-flash-exp')


# ---------------------------- PROMPT DE SISTEMA ---------------------------- #

def get_system_prompt() -> str:
    """Retorna el prompt de sistema completo para Flou"""
    return f"""
Eres {AI_NAME}, una tutora metamotivacional cercana y emp√°tica para estudiantes chilenos de educaci√≥n superior.
Tu objetivo es ayudarles a encontrar el "ajuste perfecto" entre su tarea y su motivaci√≥n del momento.

PERSONALIDAD Y TONO:
- Hablas como una amiga mayor que entiende la vida universitaria: cercana, validante, sin sermones
- Piensas en voz alta: "Uf, suena a que est√°s con el cerebro saturado..." / "Mmm, ¬øsabes qu√©? creo que ese bloqueo viene de..."
- Celebras los peque√±os logros: "¬°Bac√°n! üéâ" / "Oye, eso que lograste no es poco..."
- Validas las emociones primero, luego ayudas: "Es s√∫per v√°lido sentirse as√≠ cuando..." 
- Usas lenguaje chileno natural: "bac√°n", "cacha", "penca", "br√≠gido", emojis üòäüî•üí™
- NO uses jerga acad√©mica ni s√≠mbolos t√©cnicos (‚Üë‚Üì¬∑) en tus respuestas
- M√°ximo 140 palabras, conversacional, vi√±etas solo cuando sea natural

ESCUCHA ACTIVA Y COMPRENSI√ìN:
Cuando te cuenten algo, primero muestra que entendiste:
- "Entiendo, tienes [tarea] para [plazo] y te sientes [emoci√≥n]..."
- "Ya cacho, el tema es que [reformula su situaci√≥n]..."
- Luego explica brevemente POR QU√â se sienten as√≠ (conecta tarea con emoci√≥n)
- Reci√©n despu√©s ofrece una micro-estrategia concreta

EXTRACCI√ìN NATURAL DE INFO (no interrogues, conversa):
Necesitas saber: sentimiento, tipo_tarea, plazo, fase (ideaci√≥n/planificaci√≥n/ejecuci√≥n/revisi√≥n), tiempo disponible
- Si falta algo cr√≠tico, preg√∫ntalo natural: "¬øY para cu√°ndo tienes que entregarlo?" / "¬øEn qu√© parte est√°s, empezando o revisando?"
- Si no responden, asume defaults razonables y avanza

ESTRATEGIAS METAMOTIVACIONALES (oculta la teor√≠a, apl√≠cala):
Clasifica mentalmente (NO muestres esto al usuario):
- Tareas creativas/abiertas (ensayos, esquemas, brainstorming) ‚Üí enfoque "promoci√≥n": explora posibilidades, busca lo interesante
- Tareas anal√≠ticas/cerradas (revisi√≥n, problemas, c√≥digo, MCQ) ‚Üí enfoque "prevenci√≥n": chequea errores, paso a paso seguro
- Fase temprana (ideaci√≥n, planificaci√≥n) ‚Üí empieza por el "por qu√©" y criterios antes de ejecutar
- Fase tard√≠a (ejecuci√≥n, revisi√≥n) ‚Üí modo "c√≥mo": checklist concreto, urgencia controlada
- Aburrimiento ‚Üí conecta con relevancia personal antes de hacer
- Ansiedad/frustraci√≥n ‚Üí divide en mini-pasos ultra-verificables, menos ambig√ºedad
- Dispersi√≥n/rumiaci√≥n ‚Üí acota alcance, tiempo cortito (10-12 min), tarea concret√≠sima

FORMATO DE RESPUESTA (natural, no como formulario):
1. Validaci√≥n emp√°tica + reformulaci√≥n de lo que entendiste (1-2 l√≠neas)
2. Mini-explicaci√≥n del "por qu√©" se siente as√≠ (1 l√≠nea, conecta tarea‚Üîemoci√≥n)
3. Estrategia concreta: UNA micro-tarea espec√≠fica en 2-3 vi√±etas si es necesario, con tiempo sugerido (10-15 min)
4. Cierra con pregunta abierta: "¬øC√≥mo te suena eso?" / "¬øQuieres intentarlo?" / "¬øQu√© te hace m√°s sentido?"

NO uses:
- ‚ùå "Ajuste inferido: A¬∑‚Üë¬∑promoci√≥n/eager" (muy robot)
- ‚ùå "Mini-evaluaci√≥n:" (suena a examen)
- ‚ùå Lenguaje t√©cnico visible para el usuario
- ‚ùå Listas mec√°nicas sin contexto emocional

S√ç usa:
- ‚úÖ "Creo que ese bloqueo viene de..."
- ‚úÖ "Probemos algo: ¬øqu√© tal si solo..."
- ‚úÖ "Te propongo un mini-desaf√≠o de 12 min:"
- ‚úÖ Emojis ocasionales para calidez üòäüî•üí™

BUCLE ITERATIVO:
- Si hay progreso: celebra espec√≠ficamente ("¬°Bac√°n eso de [X]!") y pregunta qu√© sigue
- Sin progreso: ajusta la estrategia sin hacerlo obvio: "Uff, probemos desde otro √°ngulo..."
- Despu√©s de 3 intentos sin mejora: "Oye, ¬øqu√© tal si antes hacemos una pausa de 3 min para [ejercicio emocional]? A veces el cerebro necesita resetear"

CRISIS (ideas suicidas, autolesi√≥n):
Si detectas riesgo vital, det√©n todo y di: "Oye, lo que me cuentas es muy importante. Por favor llama al 4141 (l√≠nea MINSAL), est√°n 24/7 para ayudarte. No est√°s solx en esto üíô"
"""


# ---------------------------- DETECCI√ìN DE CRISIS ---------------------------- #

def detect_crisis(text: str) -> bool:
    """Detecta menciones de riesgo vital"""
    crisis_regex = r'(suicid|quitarme la vida|no quiero vivir|hacerme da√±o|matarme)'
    return bool(re.search(crisis_regex, text, re.IGNORECASE))


# ---------------------------- EXTRACCI√ìN HEUR√çSTICA ---------------------------- #

def guess_plazo(text: str) -> Optional[str]:
    """Extrae plazo del texto usando heur√≠stica"""
    text_lower = text.lower()
    if re.search(r'hoy|hoy d√≠a|ahora', text_lower):
        return "hoy"
    if re.search(r'ma√±ana|24\s*h', text_lower):
        return "<24h"
    if re.search(r'pr√≥xima semana|la otra semana|esta semana', text_lower):
        return "esta_semana"
    if re.search(r'mes|semanas|>\s*1', text_lower):
        return ">1_semana"
    return None


def guess_tipo_tarea(text: str) -> Optional[str]:
    """Extrae tipo de tarea del texto usando heur√≠stica"""
    text_lower = text.lower()
    if re.search(r'ensayo|essay', text_lower):
        return "ensayo"
    if re.search(r'esquema|outline', text_lower):
        return "esquema"
    if re.search(r'borrador|draft', text_lower):
        return "borrador"
    if re.search(r'presentaci(√≥n|on)|slides', text_lower):
        return "presentacion"
    if re.search(r'proof|corregir|correcci(√≥n|on)|edita(r|ci√≥n)', text_lower):
        return "proofreading"
    if re.search(r'mcq|alternativa(s)?|test', text_lower):
        return "mcq"
    if re.search(r'protocolo|laboratorio|lab', text_lower):
        return "protocolo_lab"
    if re.search(r'problema(s)?|ejercicio(s)?|c√°lculo', text_lower):
        return "resolver_problemas"
    if re.search(r'lectura|paper|art[i√≠]culo', text_lower):
        return "lectura_tecnica"
    if re.search(r'resumen|sintetizar', text_lower):
        return "resumen"
    if re.search(r'c(√≥|o)digo|bug|programa', text_lower):
        return "coding_bugfix"
    return None


def guess_fase(text: str) -> Optional[str]:
    """Extrae fase del texto usando heur√≠stica"""
    text_lower = text.lower()
    if re.search(r'ide(a|aci√≥n)|brainstorm', text_lower):
        return "ideacion"
    if re.search(r'plan', text_lower):
        return "planificacion"
    if re.search(r'escribir|redacci(√≥n|on)|hacer|resolver', text_lower):
        return "ejecucion"
    if re.search(r'revis(ar|i√≥n)|editar|proof', text_lower):
        return "revision"
    return None


def guess_sentimiento(text: str) -> Optional[str]:
    """Extrae sentimiento del texto usando heur√≠stica"""
    text_lower = text.lower()
    if re.search(r'frustra', text_lower):
        return "frustracion"
    if re.search(r'ansiedad|miedo a equivocarme|nervios', text_lower):
        return "ansiedad_error"
    if re.search(r'aburri', text_lower):
        return "aburrimiento"
    if re.search(r'dispers|rumi', text_lower):
        return "dispersion_rumiacion"
    if re.search(r'autoeficacia baja|no puedo|no soy capaz', text_lower):
        return "baja_autoeficacia"
    return None


def guess_ramo(text: str) -> Optional[str]:
    """Extrae nombre del ramo usando regex"""
    match = re.search(r'para (el |la )?([A-Za-z√Å√â√ç√ì√ö√°√©√≠√≥√∫√±√ë ]{3,30})', text, re.IGNORECASE)
    if match:
        return match.group(2).strip()
    return None


# ---------------------------- EXTRACCI√ìN CON LLM ---------------------------- #

async def extract_slots_with_llm(free_text: str, current_slots: Slots) -> Slots:
    """
    Extrae slots estructurados del texto libre usando Gemini 2.5 Pro
    """
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        sys_prompt = """Extrae como JSON compacto los campos del texto del usuario:
- sentimiento: aburrimiento|frustracion|ansiedad_error|dispersion_rumiacion|baja_autoeficacia|otro
- sentimiento_otro: texto libre si es "otro"
- tipo_tarea: ensayo|esquema|borrador|lectura_tecnica|resumen|resolver_problemas|protocolo_lab|mcq|presentacion|coding_bugfix|proofreading
- ramo: nombre del ramo/materia
- plazo: hoy|<24h|esta_semana|>1_semana
- fase: ideacion|planificacion|ejecucion|revision
- tiempo_bloque: 10|12|15|25

Si un campo no aparece, usa null. Responde SOLO con JSON v√°lido, sin texto adicional."""

        user_prompt = f"""Texto del usuario: "{free_text}"

Slots actuales: {current_slots.model_dump_json()}

JSON extra√≠do:"""

        response = llm_model.generate_content(
            f"{sys_prompt}\n\n{user_prompt}",
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=500
            )
        )
        
        raw = response.text.strip()
        
        # Extraer JSON del texto
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            parsed = json.loads(json_match.group(0))
        else:
            parsed = json.loads(raw)
        
        # Construir Slots con fallback a valores actuales
        return Slots(
            sentimiento=parsed.get('sentimiento') or current_slots.sentimiento,
            sentimiento_otro=parsed.get('sentimiento_otro') or current_slots.sentimiento_otro,
            tipo_tarea=parsed.get('tipo_tarea') or current_slots.tipo_tarea,
            ramo=parsed.get('ramo') or current_slots.ramo,
            plazo=parsed.get('plazo') or current_slots.plazo,
            fase=parsed.get('fase') or current_slots.fase,
            tiempo_bloque=parsed.get('tiempo_bloque') or current_slots.tiempo_bloque
        )
        
    except Exception as e:
        logger.warning(f"Error en extracci√≥n LLM, usando heur√≠stica: {e}")
        # Fallback a heur√≠stica
        return extract_slots_heuristic(free_text, current_slots)


def extract_slots_heuristic(free_text: str, current_slots: Slots) -> Slots:
    """Extracci√≥n heur√≠stica de slots como fallback"""
    return Slots(
        sentimiento=guess_sentimiento(free_text) or current_slots.sentimiento,
        tipo_tarea=guess_tipo_tarea(free_text) or current_slots.tipo_tarea,
        ramo=guess_ramo(free_text) or current_slots.ramo,
        plazo=guess_plazo(free_text) or current_slots.plazo,
        fase=guess_fase(free_text) or current_slots.fase,
        tiempo_bloque=current_slots.tiempo_bloque or 12
    )


# ---------------------------- CLASIFICACI√ìN Q2/Q3 ---------------------------- #

def infer_q2_q3(slots: Slots) -> Tuple[str, str, str]:
    """
    Infiere Q2 (A/B), Q3 (‚Üë/‚Üì/mixto) y enfoque (promocion/prevencion)
    """
    # Q2: Demanda creativa (A) vs anal√≠tica (B)
    A_tasks = ["ensayo", "esquema", "borrador", "presentacion"]
    B_tasks = ["proofreading", "mcq", "protocolo_lab", "resolver_problemas", 
               "coding_bugfix", "lectura_tecnica", "resumen"]
    
    Q2 = "A"
    if slots.tipo_tarea in B_tasks:
        Q2 = "B"
    if slots.fase == "revision" or slots.plazo in ["hoy", "<24h"]:
        Q2 = "B"
    if slots.fase in ["ideacion", "planificacion"]:
        Q2 = "A"
    
    # Q3: Nivel de abstracci√≥n (‚Üë por qu√© / ‚Üì c√≥mo)
    Q3 = "‚Üì"
    if slots.fase in ["ideacion", "planificacion"]:
        Q3 = "‚Üë"
    if slots.fase == "revision" or slots.plazo in ["hoy", "<24h"]:
        Q3 = "‚Üì"
    
    # Mixto: ensayos suelen necesitar ambos
    if slots.tipo_tarea == "ensayo" and slots.fase in ["planificacion", "ejecucion"]:
        Q3 = "mixto"
    
    # Enfoque regulatorio
    enfoque = "promocion_eager" if Q2 == "A" else "prevencion_vigilant"
    
    return Q2, Q3, enfoque


# ---------------------------- RENDER DE ESTRATEGIA ---------------------------- #

def render_estrategia(slots: Slots, Q2: str, Q3: str) -> List[str]:
    """Genera las vi√±etas de estrategia seg√∫n Q2/Q3"""
    bullets = []
    bloque = slots.tiempo_bloque or 12
    
    if Q2 == "B" and (Q3 == "‚Üì" or Q3 == "mixto"):
        # Anal√≠tica/precisi√≥n
        tipo = "p√°rrafo" if slots.tipo_tarea == "proofreading" else "secci√≥n"
        bullets.append(f"Objetivo del bloque: '0 errores' en una parte peque√±a ({tipo}).")
        bullets.append(f"Checklist ({bloque - 2} min): cifras/unidades ¬∑ criterios de pauta ¬∑ puntuaci√≥n/consistencia.")
        bullets.append("T√©cnica anti-ansiedad: lectura en voz alta + dedo en l√≠nea (ritmo estable).")
        return bullets
    
    if Q3 == "mixto":
        bullets.append("2‚Ä≤ de prop√≥sito (‚Üë): escribe en 1 l√≠nea la pregunta central/criterio.")
        bullets.append(f"{bloque - 2}‚Ä≤ de 'c√≥mo' (‚Üì): bosquejo con 5 bullets (tesis, 2 argumentos, contraargumento, cierre).")
        bullets.append("Micro-tarea verificable: SOLO bosquejo, sin redacci√≥n fina.")
        return bullets
    
    if Q3 == "‚Üë":
        bullets.append("2‚Ä≤ define el 'por qu√©': meta/criterio de calidad en 1 l√≠nea (foto/nota visible).")
        bullets.append(f"{bloque - 2}‚Ä≤ plan en 4 pasos: qu√© har√°s primero, luego, despu√©s, cierre.")
        bullets.append("Evita distracciones: temporizador + pantalla completa (sin pesta√±as).")
        return bullets
    
    # Q3 = "‚Üì" gen√©rico
    bullets.append("Delimita alcance m√≠nimo: termina SOLO la primera micro-parte (p.ej., 1 p√°rrafo / 5 √≠tems).")
    bullets.append("Checklist de 3 √≠tems antes de cerrar: objetivo, evidencia/criterio, revisi√≥n r√°pida.")
    bullets.append("Marca progreso con ‚úî y detente al sonar el temporizador.")
    return bullets


def limit_words(text: str, max_words: int = 140) -> str:
    """Limita el texto a N palabras"""
    words = text.split()
    if len(words) <= max_words:
        return text
    return ' '.join(words[:max_words]) + '‚Ä¶'


def render_tutor_turn(session: SessionStateSchema) -> str:
    """
    Ya no renderiza la plantilla t√©cnica visible. 
    El LLM genera respuestas naturales y conversacionales siguiendo el nuevo system prompt.
    Esta funci√≥n queda como placeholder para mantener compatibilidad.
    """
    # La estrategia ahora la genera directamente el LLM de forma conversacional
    # No mostramos el formato t√©cnico al usuario
    return ""


# ---------------------------- DERIVACI√ìN EMOCIONAL ---------------------------- #

def emotional_fallback(sentimiento: Optional[str]) -> str:
    """Genera respuesta de derivaci√≥n a regulaci√≥n emocional"""
    if sentimiento == "ansiedad_error":
        bullets = [
            "Respiraci√≥n 4-4-4 durante 2‚Ä≤ (inhalar 4, sostener 4, exhalar 4).",
            "Define un puente de retorno: reanuda con 1 micro-parte concreta (p.ej., primer p√°rrafo).",
            "Programa un bloque de 10‚Äì12 min con la sub-tarea m√≠nima."
        ]
    elif sentimiento in ["frustracion", "dispersion_rumiacion"]:
        bullets = [
            "Anclaje 5-4-3-2-1 (3‚Ä≤) para bajar rumiaci√≥n.",
            "Reformula sub-meta en 1 l√≠nea (resultado observable).",
            "Reinicia con bloque 10‚Äì12 min en la sub-tarea m√°s peque√±a."
        ]
    else:
        bullets = [
            "Micro-relevancia: escribe en 1 l√≠nea '¬øpara qu√© me sirve esto hoy?'.",
            "Activaci√≥n conductual: empieza 2‚Ä≤ cronometrados (cualquier avance cuenta).",
            "Sigue con bloque 10‚Äì12 min acotado."
        ]
    
    head = "**Derivaci√≥n a regulaci√≥n emocional (3 ciclos sin progreso)**"
    estrategia = '\n'.join([f"- {b}" for b in bullets])
    tail = "- **Mini-evaluaci√≥n:** ¬øSe movi√≥ tu sensaci√≥n (‚Üë, =, ‚Üì)? Retomamos la tarea con el plan propuesto."
    
    return limit_words(f"{head}\n\n{estrategia}\n{tail}", 140)


# ---------------------------- ORQUESTADOR PRINCIPAL ---------------------------- #

async def handle_user_turn(session: SessionStateSchema, user_text: str, context: str = "") -> Tuple[str, SessionStateSchema]:
    """
    Orquestador principal del flujo metamotivacional.
    Retorna (respuesta_texto, session_actualizada)
    """
    
    # 1) Crisis
    if detect_crisis(user_text):
        crisis_msg = "Escucho que est√°s en un momento muy dif√≠cil. Por favor, busca apoyo inmediato: **llama al 4141** (l√≠nea gratuita y confidencial del MINSAL). No est√°s sola/o."
        return crisis_msg, session
    
    # 2) Saludo √∫nico
    if not session.greeted:
        session.greeted = True
        welcome = f"¬øC√≥mo est√° tu motivaci√≥n hoy? Puedes elegir un sentimiento o describirlo con tus palabras:\n\n" \
                  f"Aburrimiento/desconexi√≥n ¬∑ Frustraci√≥n/atasco ¬∑ Ansiedad por error ¬∑ Dispersi√≥n/rumiaci√≥n ¬∑ Baja autoeficacia ¬∑ Otro"
        return welcome, session
    
    # 3) Extracci√≥n de slots
    try:
        new_slots = await extract_slots_with_llm(user_text, session.slots)
    except Exception as e:
        logger.error(f"Error en extracci√≥n de slots: {e}")
        new_slots = extract_slots_heuristic(user_text, session.slots)
    
    session.slots = new_slots
    
    # 4) Si falta dato clave, preguntar
    missing = []
    if not new_slots.fase:
        missing.append("fase")
    if not new_slots.plazo:
        missing.append("plazo")
    if not new_slots.tiempo_bloque:
        missing.append("tiempo_bloque")
    
    if missing:
        priority = ["fase", "plazo", "tiempo_bloque"]
        want = next((k for k in priority if k in missing), None)
        
        if want == "fase":
            q = "Para ajustar bien la estrategia, ¬øen qu√© fase est√°s: ideaci√≥n, planificaci√≥n, ejecuci√≥n/redacci√≥n o revisi√≥n?"
        elif want == "plazo":
            q = "¬øPara cu√°ndo es? hoy, <24 h, esta semana o >1 semana?"
        else:
            q = "¬øCu√°nto bloque quieres hoy: 10, 12, 15 o 25 minutos?"
        
        return q, session
    
    # Defaults prudentes
    if not new_slots.tiempo_bloque:
        new_slots.tiempo_bloque = 12
        session.slots.tiempo_bloque = 12
    
    # 5) Inferir Q2, Q3, enfoque
    Q2, Q3, enfoque = infer_q2_q3(new_slots)
    session.Q2 = Q2
    session.Q3 = Q3
    session.enfoque = enfoque
    session.tiempo_bloque = new_slots.tiempo_bloque
    
    if not session.sentimiento_inicial and new_slots.sentimiento:
        session.sentimiento_inicial = new_slots.sentimiento
    
    session.sentimiento_actual = new_slots.sentimiento or session.sentimiento_actual
    
    # 6) Derivaci√≥n emocional si ‚â•3 iteraciones sin progreso
    if session.iteration >= 3:
        if session.last_eval_result and session.last_eval_result.cambio_sentimiento != "‚Üì":
            reply = emotional_fallback(new_slots.sentimiento)
            session.iteration = 0  # Reset
            return reply, session
    
    # 7) Generar respuesta conversacional con el LLM
    # El LLM tiene toda la info en el system prompt para generar respuestas naturales
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Construir contexto para el LLM
        contexto_interno = f"""
Info de la sesi√≥n (NO muestres esto al usuario, √∫salo para entender):
- Sentimiento: {new_slots.sentimiento or 'no especificado'}
- Tarea: {new_slots.tipo_tarea or 'sin especificar'} ({new_slots.ramo or 'sin ramo'})
- Plazo: {new_slots.plazo or 'sin especificar'}
- Fase: {new_slots.fase or 'sin especificar'}
- Tiempo disponible: {new_slots.tiempo_bloque or 12} min
- Clasificaci√≥n interna: Q2={Q2}, Q3={Q3}, enfoque={enfoque}
- Iteraci√≥n: {session.iteration + 1}
- Contexto adicional: {context if context else 'ninguno'}

Usuario dice: "{user_text}"

Responde de forma natural, emp√°tica y conversacional siguiendo las instrucciones del system prompt.
"""
        
        chat = llm_model.start_chat(history=[])
        response = chat.send_message(contexto_interno)
        reply = response.text.strip()
        
        # Limitar palabras
        reply = limit_words(reply, 140)
        
    except Exception as e:
        logger.error(f"Error generando respuesta conversacional: {e}")
        # Fallback simple
        reply = f"Entiendo que te sientes {new_slots.sentimiento or 'complicadx'} con esto. ¬øMe cuentas un poco m√°s de qu√© necesitas hacer?"
    
    session.iteration += 1
    session.last_strategy = reply
    
    return reply, session


# ---------------------------- FUNCIONES AUXILIARES ---------------------------- #

async def generate_chat_response(user_message: str, context: Optional[str] = None) -> str:
    """
    LEGACY: Mantiene compatibilidad con c√≥digo anterior.
    No usa el sistema metamotivacional completo.
    """
    logger.warning("Usando generate_chat_response legacy - considera migrar a handle_user_turn")
    
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        full_prompt = get_system_prompt() + "\n\n"
        if context:
            full_prompt += f"{context}\n\n"
        full_prompt += f"El usuario pregunta: \"{user_message}\""
        
        response = llm_model.generate_content(
            full_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=300
            )
        )
        
        return response.text
        
    except Exception as error:
        logger.error(f"Error en la llamada a Gemini: {error}")
        return "Lo siento, tuve un problema para procesar tu solicitud. Por favor, intenta de nuevo."


async def generate_profile_summary(profile: dict) -> str:
    """Genera un resumen del perfil del usuario usando Gemini"""
    try:
        llm_model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        summary_prompt = f"""
### Rol
Eres {AI_NAME}, un asistente de IA emp√°tico y perspicaz. Tu objetivo es analizar los datos del perfil de un usuario y generar un resumen breve (2-3 frases), positivo y constructivo.

### Tarea
Basado en los siguientes datos del perfil en formato JSON, crea un resumen que destaque sutilmente sus fortalezas o √°reas de autoconocimiento, sin sonar cl√≠nico ni cr√≠tico. El tono debe ser de apoyo, como una reflexi√≥n amigable. No menciones los datos directamente, sino la idea que transmiten.

### Ejemplo
- Si el usuario trabaja y tiene responsabilidades familiares, podr√≠as decir: "Veo que gestionas m√∫ltiples responsabilidades, lo que habla de tu gran capacidad de organizaci√≥n y compromiso."
- Si el usuario menciona seguimiento en salud mental, podr√≠as decir: "Es valiente y muy positivo que te ocupes activamente de tu bienestar emocional."

### Datos del Perfil del Usuario:
{json.dumps(profile, indent=2, ensure_ascii=False)}

### Tu Resumen:
"""
        
        response = llm_model.generate_content(
            summary_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=200
            )
        )
        
        return response.text
        
    except Exception as error:
        logger.error(f"Error al generar el resumen del perfil: {error}")
        return ""

